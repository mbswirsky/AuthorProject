{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "Analyzes texts from seemingly-similar authors, Rachel Swirsky, Cat Valente, and Carmen Maria Machado, on a sentence-by-sentence basis, to see if their writing styles can be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data\n",
    "\n",
    "### Requesting and parsing html\n",
    "* Using requests and BeautifulSoup\n",
    "* The program first pulls stories directly from their published websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get raw in 11.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# Pull stories from their websites\n",
    "\n",
    "header={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'}\n",
    "\n",
    "def get_raw(url, no_strong=False, no_b=False):\n",
    "    response = requests.get(url, headers=header)\n",
    "#     req = Request(url, headers=header)\n",
    "    html = response.content\n",
    "#     html = urlopen(req).read().decode('utf8')\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    if no_strong == True:\n",
    "        for strong in soup('strong'):\n",
    "            strong.decompose()\n",
    "    if no_b == True:\n",
    "        for b in soup('b'):\n",
    "            b.decompose()\n",
    "    return soup.get_text()\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# Swirsky stories\n",
    "dino_raw = get_raw('https://www.apex-magazine.com/if-you-were-a-dinosaur-my-love/')\n",
    "\n",
    "eros_raw = get_raw('https://www.tor.com/2009/03/03/eros-philia-agape/')\n",
    "\n",
    "still_raw = get_raw('http://uncannymagazine.com/article/love-is-never-still/', no_b=True)\n",
    "\n",
    "# Valente stories\n",
    "fade_raw = get_raw('http://clarkesworldmagazine.com/valente_08_12/')\n",
    "\n",
    "silent1_raw = get_raw('http://clarkesworldmagazine.com/valente_10_11/', no_strong=True)\n",
    "\n",
    "silent2_raw = get_raw('http://clarkesworldmagazine.com/valente_11_11/', no_strong=True)\n",
    "\n",
    "silent3_raw = get_raw('http://clarkesworldmagazine.com/valente_12_11/', no_strong=True)\n",
    "\n",
    "lion_raw = get_raw('http://uncannymagazine.com/article/planet-lion/')\n",
    "\n",
    "# Machado stories\n",
    "stitch_raw = get_raw('https://granta.com/The-Husband-Stitch/')\n",
    "\n",
    "follow_raw = get_raw('http://www.lightspeedmagazine.com/fiction/help-follow-sister-land-dead/')\n",
    "\n",
    "descent_raw = get_raw('http://www.nightmare-magazine.com/fiction/descent/')\n",
    "\n",
    "bites_raw = get_raw('http://texas.gulfcoastmag.org/journal/29.2-summer/fall-2017/eight-bites/')\n",
    "\n",
    "print('Get raw in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding story text in html\n",
    "* Using find() from BeautifulSoup\n",
    "* Identifies story text inside the total site text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select out story text\n",
    "\n",
    "def select_out(raw, start_text, end_text):\n",
    "    start = raw.find(start_text)\n",
    "    end = raw.find(end_text)\n",
    "    return raw[start:end+len(end_text)]\n",
    "\n",
    "dinosaur = select_out(dino_raw, \n",
    "                      'If you were a dinosaur, my', \n",
    "                      ', and the stuttering of my broken heart.'\n",
    "                     )\n",
    "eros = select_out(eros_raw, \n",
    "                  'Lucian packed his possessions before he left.', \n",
    "                  'yet form the thoughts to wonder what will happen next.\\nHe moves on.'\n",
    "                 )\n",
    "still = select_out(still_raw, \n",
    "                  'Through every moment of carving, I want her as one wants a woman. I want', \n",
    "                  'and decay, but it is also the early bloom that opens into winter’s cold. She is love, and she will always be reborn.'\n",
    "                  )\n",
    "fade = select_out(fade_raw, \n",
    "                 'ZOOM IN on a bright-eyed Betty in a crisp green dress,', \n",
    "                 'And over the black, a cheerful fat man giving the thumbs up to Sylvie, grinning:\\n\\nBuy Freedom Brand Film! It\\'s A-OK!'\n",
    "                 )\n",
    "silent1 = select_out(silent1_raw, \n",
    "                    'Inanna was called Queen of Heaven and Earth,', \n",
    "                    'The sun breaks the mountain crests, hard and cold, a shaft of white spilling over the black lake.'\n",
    "                    )\n",
    "silent2 = select_out(silent2_raw, \n",
    "                    'Humanity lived many years and ruled the earth,', \n",
    "                    'The castle windows go dark, one by one.'\n",
    "                    )\n",
    "silent3 = select_out(silent3_raw, \n",
    "                    'Tell me a story about yourself, Elefsis.', \n",
    "                    'we walk up the long path out of the churning, honey-colored sea.'\n",
    "                    )\n",
    "silent = silent1 + '\\n' + silent2 + '\\n' + silent3\n",
    "\n",
    "lion = select_out(lion_raw, \n",
    "                 'Initial Survey Report: Planet 6MQ441 (Bakeneko), Alaraph', \n",
    "                 'Szent Istvan. She longs to hear the first roar of her young.'\n",
    "                 )\n",
    "stitch = select_out(stitch_raw, \n",
    "                   '(If you read this story out loud, please use', \n",
    "                   'backwards off my neck and rolls off the bed, I feel as lonely as I have ever been.'\n",
    "                   )\n",
    "follow = select_out(follow_raw, \n",
    "                   'Help Me Follow My Sister\\ninto the Land of the Dead\\nby Ursula Ruiz', \n",
    "                   's—in a terrifying place where no mortal has any business treading.'\n",
    "                   ) + '\\n' + select_out(follow_raw, \n",
    "                                        'Home\\nThis is the thing about my sister and I:', \n",
    "                                        'Lucille L\\nJun 28, 2015\\nUrsula?'\n",
    "                                        )\n",
    "descent = select_out(descent_raw, \n",
    "                    'We gathered for the last time in October,', \n",
    "                    ', drinks cocked in their hands.\\nI looked down.'\n",
    "                    )\n",
    "bites = select_out(bites_raw, \n",
    "                  'As they put me to sleep, my mouth fills with the dust of the moon. I expect to choke on the silt but', \n",
    "                  'my charge.\\\"I\\'m sorry,\\\" I will whisper into her as she walks me toward the front door.\\\"I\\'m sorry,\\\" I will repeat. \\\"I didn\\'t know.\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Text\n",
    "\n",
    "### Cleaning \n",
    "* Cleaning out un-parseable symbols\n",
    "* Using re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(r'[\\[\\]]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean out bad symbols\n",
    "dinosaur = text_cleaner(dinosaur)\n",
    "eros = text_cleaner(eros)\n",
    "fade = text_cleaner(fade)\n",
    "silent = text_cleaner(silent)\n",
    "lion = text_cleaner(lion)\n",
    "still = text_cleaner(still)\n",
    "stitch = text_cleaner(stitch)\n",
    "follow = text_cleaner(follow)\n",
    "descent = text_cleaner(descent)\n",
    "bites = text_cleaner(bites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing documents\n",
    "* Using spaCy\n",
    "* Identifies sentence structure in the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed in 26.64 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parse using spaCy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "dinosaur_doc = nlp(dinosaur)\n",
    "eros_doc = nlp(eros)\n",
    "fade_doc = nlp(fade)\n",
    "silent_doc = nlp(silent)\n",
    "lion_doc = nlp(lion)\n",
    "still_doc = nlp(still)\n",
    "stitch_doc = nlp(stitch)\n",
    "follow_doc = nlp(follow)\n",
    "descent_doc = nlp(descent)\n",
    "bites_doc = nlp(bites)\n",
    "\n",
    "print('Parsed in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print([sent.lemma_ for sent in eros_doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data into sentences\n",
    "* We undo spaCy's tokenization, just keeping the data split into sentences\n",
    "* Creates one table of all the data, organized with one sentence for each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group sentences with their authors. (Each sentence will be a row.)\n",
    "\n",
    "dinosaur_sents = [[sent.string, \"Swirsky\"] for sent in dinosaur_doc.sents]\n",
    "eros_sents = [[sent.string, \"Swirsky\"] for sent in eros_doc.sents]\n",
    "still_sents = [[sent.string, \"Swirsky\"] for sent in still_doc.sents]\n",
    "fade_sents = [[sent.string, \"Valente\"] for sent in fade_doc.sents]\n",
    "silent_sents = [[sent.string, \"Valente\"] for sent in silent_doc.sents]\n",
    "lion_sents = [[sent.string, \"Valente\"] for sent in lion_doc.sents]\n",
    "stitch_sents = [[sent.string, \"Machado\"] for sent in stitch_doc.sents]\n",
    "follow_sents = [[sent.string, \"Machado\"] for sent in follow_doc.sents]\n",
    "descent_sents = [[sent.string, \"Machado\"] for sent in descent_doc.sents]\n",
    "bites_sents = [[sent.string, \"Machado\"] for sent in bites_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>2269</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>1880</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>1603</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  ratio\n",
       "Valente   2269   0.39\n",
       "Swirsky   1880   0.33\n",
       "Machado   1603   0.28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5752 total sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if you were a dinosaur  my love  then you woul...</td>\n",
       "      <td>Swirsky</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author  words\n",
       "0  if you were a dinosaur  my love  then you woul...  Swirsky     14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>was called queen of heaven and earth  queen o...</td>\n",
       "      <td>Valente</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   author  words\n",
       "2153   was called queen of heaven and earth  queen o...  Valente     37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>if you read this story out loud  please use t...</td>\n",
       "      <td>Machado</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   author  words\n",
       "4486   if you read this story out loud  please use t...  Machado     24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the sentences from the stories into one data frame.\n",
    "sentences = pd.DataFrame(dinosaur_sents + eros_sents + still_sents + fade_sents + silent_sents + lion_sents + stitch_sents + follow_sents + descent_sents + bites_sents)\n",
    "sentences.columns = ['text', 'author']\n",
    "\n",
    "# Strip out unnecessary punctuation.\n",
    "sentences['text'] = sentences['text'].str.lower().str.replace(r'[^a-zA-Z0-9 ]+', ' ').fillna('')\n",
    "\n",
    "# Word count per sentence.\n",
    "sentences['words'] = sentences['text'].str.split().apply(len)\n",
    "\n",
    "# Remove blank sentences.\n",
    "sentences = sentences.loc[sentences['words'] > 0]\n",
    "\n",
    "# Remove proper nouns personal to each document.\n",
    "propn_pat = r'\\b(agogna|koetoi|adriana|lucian|galatea|aphrodite|hephaestus|fuoco|inanna|enki|erishkigal|salma|janet|lawrence|olive|luna|ursula|ceno|neva|elefsis|ravan|cassian|diane|ares|ben|seki|ilet)\\b'\n",
    "sentences['text'] = sentences['text'].str.replace(propn_pat, '')\n",
    "\n",
    "# Sentence counts by author.\n",
    "df_count = sentences.author.value_counts().to_frame(name='count')\n",
    "df_count['ratio'] = (df_count['count'] / len(sentences.author)).round(2)\n",
    "print('Full Data Set:')\n",
    "display(df_count)\n",
    "print('{} total sentences'.format(len(sentences.author)))\n",
    "display(sentences.loc[sentences['author'] == 'Swirsky'].head(1))\n",
    "display(sentences.loc[sentences['author'] == 'Valente'].head(1))\n",
    "display(sentences.loc[sentences['author'] == 'Machado'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Test Set\n",
    "This protects the vectorizer and regressor from over-fitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences['text'], sentences['author'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "         count\n",
      "Valente   1833\n",
      "Swirsky   1495\n",
      "Machado   1273\n",
      "\n",
      "Test Set:\n",
      "         count\n",
      "Valente    436\n",
      "Swirsky    385\n",
      "Machado    330\n"
     ]
    }
   ],
   "source": [
    "print('Training Set:')\n",
    "print(y_train.value_counts().to_frame(name='count'))\n",
    "print('\\nTest Set:')\n",
    "print(y_test.value_counts().to_frame(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Vectorizer and Estimators\n",
    "\n",
    "### TFIDF Vectorizer\n",
    "\n",
    "* Try most common words across all texts\n",
    "* Bigrams and trigrams are arrangements of two- and three-words, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=str.split, \n",
    "                            stop_words='english', \n",
    "                            lowercase=True, \n",
    "                            use_idf=True, \n",
    "                            norm='l2', \n",
    "                            smooth_idf=True, \n",
    "                            max_features=None, \n",
    "                            ngram_range=(1,3), \n",
    "                            max_df=0.6, \n",
    "                            min_df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier\n",
    "* Combines support vector classifier with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(penalty='elasticnet', \n",
    "                    alpha=0.0001, \n",
    "                    class_weight=None, \n",
    "                    loss='log', \n",
    "                    tol=0.005, \n",
    "                    fit_intercept=True, \n",
    "                    power_t=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* Chains vectorizer and estimator as input to grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vect', vectorizer), ('model', sgd)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Parameters\n",
    "* List parameters to search over for best cv fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_features = [None, 20000, 10000, 5000, 1000]\n",
    "vect_ngrams = [(1,1), (1,2), (1,3)]\n",
    "vect_max = [0.6, 0.7, 0.8]\n",
    "vect_min = [1, 2, 3]\n",
    "vect_norm = ['l2', 'l1', None]\n",
    "lsa_n = [1000, 500, 100]\n",
    "model_alpha = [0.001, 0.0001, 0.00001]\n",
    "model_loss = ['hinge', 'log', 'squared_hinge', 'perceptron']\n",
    "model_tol = [0.01, 0.005, 0.001]\n",
    "model_class_weight = ['balanced', None]\n",
    "model_power_t = [0.4, 0.5, 0.6]\n",
    "model_penalty = ['l2', 'elasticnet', 'l1', 'none']\n",
    "model_intercept = [True, False]\n",
    "\n",
    "parameters = {\n",
    "        'vect__max_features': vect_features, \n",
    "        'vect__ngram_range': vect_ngrams, \n",
    "#         'vect__max_df': vect_max, \n",
    "#         'vect__min_df': vect_min, \n",
    "#         'vect__norm': vect_norm, \n",
    "#         'lsa__n_components': lsa_n, \n",
    "#         'model__alpha': model_alpha, \n",
    "#         'model__loss': model_loss, \n",
    "#         'model__tol': model_tol,\n",
    "#         'model__class_weight': model_class_weight, \n",
    "#         'model__power_t': model_power_t, \n",
    "#         'model__penalty': model_penalty, \n",
    "#         'model__fit_intercept': model_intercept\n",
    "    }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    parameters, \n",
    "                    scoring='f1_weighted', \n",
    "                    return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "\n",
      "Completed in 6.16 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Performing grid search...')\n",
    "t0 = time()\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\nCompleted in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Training Set Score: 93.49%\n",
      "\n",
      "Best Cross-Val Score: 65.37%\n",
      "\n",
      "Best Parameters:\n",
      "\n",
      "vect__max_features: 10000\n",
      "vect__ngram_range: (1, 3)\n",
      "\n",
      "Test set score: 67.6%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Author</th>\n",
       "      <th>Machado</th>\n",
       "      <th>Swirsky</th>\n",
       "      <th>Valente</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>178</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>36</td>\n",
       "      <td>260</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Author  Machado  Swirsky  Valente\n",
       "Actual Author                              \n",
       "Machado               178       69       83\n",
       "Swirsky                36      260       89\n",
       "Valente                49       42      345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7822 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ribbon</th>\n",
       "      <th>parents</th>\n",
       "      <th>i</th>\n",
       "      <th>cal</th>\n",
       "      <th>doctor</th>\n",
       "      <th>my</th>\n",
       "      <th>going</th>\n",
       "      <th>son</th>\n",
       "      <th>says</th>\n",
       "      <th>woman</th>\n",
       "      <th>there</th>\n",
       "      <th>girl</th>\n",
       "      <th>please</th>\n",
       "      <th>why</th>\n",
       "      <th>students</th>\n",
       "      <th>2015</th>\n",
       "      <th>husband</th>\n",
       "      <th>class</th>\n",
       "      <th>shooting</th>\n",
       "      <th>sister</th>\n",
       "      <th>tell</th>\n",
       "      <th>here</th>\n",
       "      <th>next</th>\n",
       "      <th>heard</th>\n",
       "      <th>school</th>\n",
       "      <th>room</th>\n",
       "      <th>nurse</th>\n",
       "      <th>surgery</th>\n",
       "      <th>hear</th>\n",
       "      <th>beneath</th>\n",
       "      <th>week</th>\n",
       "      <th>back</th>\n",
       "      <th>around</th>\n",
       "      <th>girlfriend</th>\n",
       "      <th>slender</th>\n",
       "      <th>asks</th>\n",
       "      <th>5</th>\n",
       "      <th>streets</th>\n",
       "      <th>boy</th>\n",
       "      <th>after</th>\n",
       "      <th>been</th>\n",
       "      <th>just</th>\n",
       "      <th>jun</th>\n",
       "      <th>1</th>\n",
       "      <th>touch</th>\n",
       "      <th>oysters</th>\n",
       "      <th>she</th>\n",
       "      <th>kind</th>\n",
       "      <th>toes</th>\n",
       "      <th>backers</th>\n",
       "      <th>...</th>\n",
       "      <th>heat</th>\n",
       "      <th>smallgod</th>\n",
       "      <th>make</th>\n",
       "      <th>her</th>\n",
       "      <th>human</th>\n",
       "      <th>princess</th>\n",
       "      <th>sun</th>\n",
       "      <th>quite</th>\n",
       "      <th>us</th>\n",
       "      <th>watch</th>\n",
       "      <th>every</th>\n",
       "      <th>men</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>queen</th>\n",
       "      <th>brother</th>\n",
       "      <th>steelveldt</th>\n",
       "      <th>machine</th>\n",
       "      <th>upon</th>\n",
       "      <th>inside</th>\n",
       "      <th>uplink</th>\n",
       "      <th>lonely</th>\n",
       "      <th>d</th>\n",
       "      <th>lived</th>\n",
       "      <th>hate</th>\n",
       "      <th>knew</th>\n",
       "      <th>their</th>\n",
       "      <th>held</th>\n",
       "      <th>wants</th>\n",
       "      <th>blue</th>\n",
       "      <th>trees</th>\n",
       "      <th>hope</th>\n",
       "      <th>dormouse</th>\n",
       "      <th>too</th>\n",
       "      <th>love</th>\n",
       "      <th>bird</th>\n",
       "      <th>called</th>\n",
       "      <th>robot</th>\n",
       "      <th>sea</th>\n",
       "      <th>stand</th>\n",
       "      <th>ivory</th>\n",
       "      <th>made</th>\n",
       "      <th>could</th>\n",
       "      <th>cannot</th>\n",
       "      <th>loved</th>\n",
       "      <th>lions</th>\n",
       "      <th>big</th>\n",
       "      <th>must</th>\n",
       "      <th>lion</th>\n",
       "      <th>rose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>3.974845</td>\n",
       "      <td>3.919196</td>\n",
       "      <td>3.605472</td>\n",
       "      <td>3.580084</td>\n",
       "      <td>3.496119</td>\n",
       "      <td>3.364507</td>\n",
       "      <td>3.256018</td>\n",
       "      <td>3.157463</td>\n",
       "      <td>2.950417</td>\n",
       "      <td>2.846457</td>\n",
       "      <td>2.699319</td>\n",
       "      <td>2.681041</td>\n",
       "      <td>2.626904</td>\n",
       "      <td>2.598042</td>\n",
       "      <td>2.541305</td>\n",
       "      <td>2.491888</td>\n",
       "      <td>2.476677</td>\n",
       "      <td>2.432863</td>\n",
       "      <td>2.363321</td>\n",
       "      <td>2.343317</td>\n",
       "      <td>2.335425</td>\n",
       "      <td>2.311473</td>\n",
       "      <td>2.305131</td>\n",
       "      <td>2.282672</td>\n",
       "      <td>2.266654</td>\n",
       "      <td>2.244174</td>\n",
       "      <td>2.236107</td>\n",
       "      <td>2.233140</td>\n",
       "      <td>2.228633</td>\n",
       "      <td>2.179760</td>\n",
       "      <td>2.172717</td>\n",
       "      <td>2.134275</td>\n",
       "      <td>2.113243</td>\n",
       "      <td>2.096146</td>\n",
       "      <td>2.093129</td>\n",
       "      <td>2.075203</td>\n",
       "      <td>2.074968</td>\n",
       "      <td>2.067010</td>\n",
       "      <td>2.058032</td>\n",
       "      <td>2.040202</td>\n",
       "      <td>2.020905</td>\n",
       "      <td>2.007402</td>\n",
       "      <td>2.006837</td>\n",
       "      <td>1.985219</td>\n",
       "      <td>1.973784</td>\n",
       "      <td>1.963549</td>\n",
       "      <td>1.921005</td>\n",
       "      <td>1.907875</td>\n",
       "      <td>1.907063</td>\n",
       "      <td>1.897791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.320322</td>\n",
       "      <td>-1.324618</td>\n",
       "      <td>-1.344043</td>\n",
       "      <td>-1.366630</td>\n",
       "      <td>-1.371039</td>\n",
       "      <td>-1.376662</td>\n",
       "      <td>-1.385792</td>\n",
       "      <td>-1.389133</td>\n",
       "      <td>-1.392143</td>\n",
       "      <td>-1.407096</td>\n",
       "      <td>-1.418690</td>\n",
       "      <td>-1.431624</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>-1.471301</td>\n",
       "      <td>-1.500333</td>\n",
       "      <td>-1.517608</td>\n",
       "      <td>-1.518525</td>\n",
       "      <td>-1.530101</td>\n",
       "      <td>-1.612971</td>\n",
       "      <td>-1.614615</td>\n",
       "      <td>-1.622697</td>\n",
       "      <td>-1.638078</td>\n",
       "      <td>-1.642701</td>\n",
       "      <td>-1.648844</td>\n",
       "      <td>-1.692939</td>\n",
       "      <td>-1.695908</td>\n",
       "      <td>-1.701796</td>\n",
       "      <td>-1.724241</td>\n",
       "      <td>-1.742081</td>\n",
       "      <td>-1.745980</td>\n",
       "      <td>-1.757863</td>\n",
       "      <td>-1.779758</td>\n",
       "      <td>-1.801345</td>\n",
       "      <td>-1.898607</td>\n",
       "      <td>-2.053991</td>\n",
       "      <td>-2.135795</td>\n",
       "      <td>-2.139092</td>\n",
       "      <td>-2.147025</td>\n",
       "      <td>-2.150524</td>\n",
       "      <td>-2.157837</td>\n",
       "      <td>-2.183235</td>\n",
       "      <td>-2.241718</td>\n",
       "      <td>-2.258107</td>\n",
       "      <td>-2.323451</td>\n",
       "      <td>-2.425863</td>\n",
       "      <td>-2.496075</td>\n",
       "      <td>-2.536800</td>\n",
       "      <td>-3.134724</td>\n",
       "      <td>-4.800011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>-2.268152</td>\n",
       "      <td>-1.703086</td>\n",
       "      <td>-4.161711</td>\n",
       "      <td>-1.451850</td>\n",
       "      <td>-1.587053</td>\n",
       "      <td>-1.104871</td>\n",
       "      <td>-1.348633</td>\n",
       "      <td>-2.060466</td>\n",
       "      <td>-4.162776</td>\n",
       "      <td>0.327939</td>\n",
       "      <td>-0.994165</td>\n",
       "      <td>-1.300862</td>\n",
       "      <td>-1.850840</td>\n",
       "      <td>-0.782955</td>\n",
       "      <td>-1.004251</td>\n",
       "      <td>-1.398887</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>-1.226323</td>\n",
       "      <td>-1.033813</td>\n",
       "      <td>-1.758987</td>\n",
       "      <td>-1.511646</td>\n",
       "      <td>-0.530247</td>\n",
       "      <td>-1.219084</td>\n",
       "      <td>-0.913386</td>\n",
       "      <td>-1.392004</td>\n",
       "      <td>-0.163792</td>\n",
       "      <td>-1.142193</td>\n",
       "      <td>-1.524278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.173321</td>\n",
       "      <td>-0.860898</td>\n",
       "      <td>-1.578314</td>\n",
       "      <td>-0.978136</td>\n",
       "      <td>-0.805445</td>\n",
       "      <td>-0.905920</td>\n",
       "      <td>-1.851282</td>\n",
       "      <td>-1.009442</td>\n",
       "      <td>-1.125945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.074626</td>\n",
       "      <td>-0.437971</td>\n",
       "      <td>-1.989908</td>\n",
       "      <td>-1.173786</td>\n",
       "      <td>-0.919255</td>\n",
       "      <td>-0.470975</td>\n",
       "      <td>-0.635709</td>\n",
       "      <td>0.648838</td>\n",
       "      <td>-1.168619</td>\n",
       "      <td>-0.987558</td>\n",
       "      <td>-0.987287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.300724</td>\n",
       "      <td>-1.628849</td>\n",
       "      <td>0.905815</td>\n",
       "      <td>0.601825</td>\n",
       "      <td>-0.765427</td>\n",
       "      <td>-1.536956</td>\n",
       "      <td>1.804851</td>\n",
       "      <td>-0.868509</td>\n",
       "      <td>-0.366140</td>\n",
       "      <td>1.301443</td>\n",
       "      <td>-0.160906</td>\n",
       "      <td>1.743821</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-0.072947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.722126</td>\n",
       "      <td>-1.384145</td>\n",
       "      <td>0.438450</td>\n",
       "      <td>-1.741765</td>\n",
       "      <td>-1.307520</td>\n",
       "      <td>-0.991167</td>\n",
       "      <td>4.845712</td>\n",
       "      <td>-0.495798</td>\n",
       "      <td>-0.527069</td>\n",
       "      <td>-0.212201</td>\n",
       "      <td>0.112725</td>\n",
       "      <td>1.406662</td>\n",
       "      <td>-1.196232</td>\n",
       "      <td>-1.033375</td>\n",
       "      <td>1.550632</td>\n",
       "      <td>1.115473</td>\n",
       "      <td>-1.797952</td>\n",
       "      <td>0.601976</td>\n",
       "      <td>4.176348</td>\n",
       "      <td>3.155047</td>\n",
       "      <td>-1.022373</td>\n",
       "      <td>1.995306</td>\n",
       "      <td>-0.497472</td>\n",
       "      <td>0.773474</td>\n",
       "      <td>3.545670</td>\n",
       "      <td>-0.436078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.052546</td>\n",
       "      <td>0.851641</td>\n",
       "      <td>-3.271085</td>\n",
       "      <td>-1.885389</td>\n",
       "      <td>3.222733</td>\n",
       "      <td>-3.567136</td>\n",
       "      <td>7.166028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>-2.164409</td>\n",
       "      <td>-2.042637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.314492</td>\n",
       "      <td>-2.029777</td>\n",
       "      <td>-2.139792</td>\n",
       "      <td>-2.204059</td>\n",
       "      <td>-1.409897</td>\n",
       "      <td>0.292788</td>\n",
       "      <td>-3.531082</td>\n",
       "      <td>-1.458367</td>\n",
       "      <td>-1.313324</td>\n",
       "      <td>-1.194753</td>\n",
       "      <td>-1.886176</td>\n",
       "      <td>-1.582846</td>\n",
       "      <td>-1.262897</td>\n",
       "      <td>-2.332120</td>\n",
       "      <td>-1.428208</td>\n",
       "      <td>-1.323719</td>\n",
       "      <td>-0.758352</td>\n",
       "      <td>-1.192370</td>\n",
       "      <td>-1.698537</td>\n",
       "      <td>-1.227302</td>\n",
       "      <td>-1.305384</td>\n",
       "      <td>-0.979343</td>\n",
       "      <td>-1.970271</td>\n",
       "      <td>-0.845996</td>\n",
       "      <td>-0.712293</td>\n",
       "      <td>-1.958914</td>\n",
       "      <td>-1.862371</td>\n",
       "      <td>-1.371674</td>\n",
       "      <td>-0.651012</td>\n",
       "      <td>-1.106554</td>\n",
       "      <td>-1.409201</td>\n",
       "      <td>-1.270322</td>\n",
       "      <td>-0.112739</td>\n",
       "      <td>-0.834237</td>\n",
       "      <td>-0.803823</td>\n",
       "      <td>-2.125012</td>\n",
       "      <td>-0.765138</td>\n",
       "      <td>-1.336353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.009737</td>\n",
       "      <td>-1.037380</td>\n",
       "      <td>-1.567137</td>\n",
       "      <td>-1.066487</td>\n",
       "      <td>-2.523657</td>\n",
       "      <td>-0.585338</td>\n",
       "      <td>-0.560382</td>\n",
       "      <td>-0.809848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631435</td>\n",
       "      <td>0.415629</td>\n",
       "      <td>0.521620</td>\n",
       "      <td>1.717451</td>\n",
       "      <td>2.748941</td>\n",
       "      <td>-0.530921</td>\n",
       "      <td>2.236426</td>\n",
       "      <td>1.741254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348325</td>\n",
       "      <td>-0.125701</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>1.475925</td>\n",
       "      <td>1.320127</td>\n",
       "      <td>2.962847</td>\n",
       "      <td>2.585487</td>\n",
       "      <td>0.898558</td>\n",
       "      <td>2.683822</td>\n",
       "      <td>2.617961</td>\n",
       "      <td>2.482070</td>\n",
       "      <td>-3.646938</td>\n",
       "      <td>1.852829</td>\n",
       "      <td>1.776739</td>\n",
       "      <td>1.885260</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.258668</td>\n",
       "      <td>2.850734</td>\n",
       "      <td>2.330612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373994</td>\n",
       "      <td>3.152764</td>\n",
       "      <td>0.771258</td>\n",
       "      <td>-2.766039</td>\n",
       "      <td>-1.500564</td>\n",
       "      <td>2.224121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.368000</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>-1.683480</td>\n",
       "      <td>2.347955</td>\n",
       "      <td>1.897286</td>\n",
       "      <td>0.217676</td>\n",
       "      <td>0.713571</td>\n",
       "      <td>4.483299</td>\n",
       "      <td>3.963153</td>\n",
       "      <td>-1.024925</td>\n",
       "      <td>5.254740</td>\n",
       "      <td>-4.342088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ribbon   parents         i       cal    doctor        my     going  \\\n",
       "Machado  3.974845  3.919196  3.605472  3.580084  3.496119  3.364507  3.256018   \n",
       "Swirsky -2.268152 -1.703086 -4.161711 -1.451850 -1.587053 -1.104871 -1.348633   \n",
       "Valente -2.164409 -2.042637  0.000000 -2.314492 -2.029777 -2.139792 -2.204059   \n",
       "\n",
       "              son      says     woman     there      girl    please       why  \\\n",
       "Machado  3.157463  2.950417  2.846457  2.699319  2.681041  2.626904  2.598042   \n",
       "Swirsky -2.060466 -4.162776  0.327939 -0.994165 -1.300862 -1.850840 -0.782955   \n",
       "Valente -1.409897  0.292788 -3.531082 -1.458367 -1.313324 -1.194753 -1.886176   \n",
       "\n",
       "         students      2015   husband     class  shooting    sister      tell  \\\n",
       "Machado  2.541305  2.491888  2.476677  2.432863  2.363321  2.343317  2.335425   \n",
       "Swirsky -1.004251 -1.398887 -0.228277 -1.226323 -1.033813 -1.758987 -1.511646   \n",
       "Valente -1.582846 -1.262897 -2.332120 -1.428208 -1.323719 -0.758352 -1.192370   \n",
       "\n",
       "             here      next     heard    school      room     nurse   surgery  \\\n",
       "Machado  2.311473  2.305131  2.282672  2.266654  2.244174  2.236107  2.233140   \n",
       "Swirsky -0.530247 -1.219084 -0.913386 -1.392004 -0.163792 -1.142193 -1.524278   \n",
       "Valente -1.698537 -1.227302 -1.305384 -0.979343 -1.970271 -0.845996 -0.712293   \n",
       "\n",
       "             hear   beneath      week      back    around  girlfriend  \\\n",
       "Machado  2.228633  2.179760  2.172717  2.134275  2.113243    2.096146   \n",
       "Swirsky  0.000000 -0.173321 -0.860898 -1.578314 -0.978136   -0.805445   \n",
       "Valente -1.958914 -1.862371 -1.371674 -0.651012 -1.106554   -1.409201   \n",
       "\n",
       "          slender      asks         5   streets       boy     after      been  \\\n",
       "Machado  2.093129  2.075203  2.074968  2.067010  2.058032  2.040202  2.020905   \n",
       "Swirsky -0.905920 -1.851282 -1.009442 -1.125945  0.000000 -1.074626 -0.437971   \n",
       "Valente -1.270322 -0.112739 -0.834237 -0.803823 -2.125012 -0.765138 -1.336353   \n",
       "\n",
       "             just       jun         1     touch   oysters       she      kind  \\\n",
       "Machado  2.007402  2.006837  1.985219  1.973784  1.963549  1.921005  1.907875   \n",
       "Swirsky -1.989908 -1.173786 -0.919255 -0.470975 -0.635709  0.648838 -1.168619   \n",
       "Valente  0.000000 -1.009737 -1.037380 -1.567137 -1.066487 -2.523657 -0.585338   \n",
       "\n",
       "             toes   backers    ...         heat  smallgod      make       her  \\\n",
       "Machado  1.907063  1.897791    ...    -1.320322 -1.324618 -1.344043 -1.366630   \n",
       "Swirsky -0.987558 -0.987287    ...     1.300724 -1.628849  0.905815  0.601825   \n",
       "Valente -0.560382 -0.809848    ...     0.000000  2.631435  0.415629  0.521620   \n",
       "\n",
       "            human  princess       sun     quite        us     watch     every  \\\n",
       "Machado -1.371039 -1.376662 -1.385792 -1.389133 -1.392143 -1.407096 -1.418690   \n",
       "Swirsky -0.765427 -1.536956  1.804851 -0.868509 -0.366140  1.301443 -0.160906   \n",
       "Valente  1.717451  2.748941 -0.530921  2.236426  1.741254  0.000000  1.348325   \n",
       "\n",
       "              men      hole  watering     queen   brother  steelveldt  \\\n",
       "Machado -1.431624 -1.433109 -1.433109 -1.471301 -1.500333   -1.517608   \n",
       "Swirsky  1.743821 -1.886024 -1.886024 -0.072947  0.000000   -1.722126   \n",
       "Valente -0.125701  2.714336  2.714336  1.475925  1.320127    2.962847   \n",
       "\n",
       "          machine      upon    inside    uplink    lonely         d     lived  \\\n",
       "Machado -1.518525 -1.530101 -1.612971 -1.614615 -1.622697 -1.638078 -1.642701   \n",
       "Swirsky -1.384145  0.438450 -1.741765 -1.307520 -0.991167  4.845712 -0.495798   \n",
       "Valente  2.585487  0.898558  2.683822  2.617961  2.482070 -3.646938  1.852829   \n",
       "\n",
       "             hate      knew     their      held     wants      blue     trees  \\\n",
       "Machado -1.648844 -1.692939 -1.695908 -1.701796 -1.724241 -1.742081 -1.745980   \n",
       "Swirsky -0.527069 -0.212201  0.112725  1.406662 -1.196232 -1.033375  1.550632   \n",
       "Valente  1.776739  1.885260  0.984937  0.258668  2.850734  2.330612  0.000000   \n",
       "\n",
       "             hope  dormouse       too      love      bird    called     robot  \\\n",
       "Machado -1.757863 -1.779758 -1.801345 -1.898607 -2.053991 -2.135795 -2.139092   \n",
       "Swirsky  1.115473 -1.797952  0.601976  4.176348  3.155047 -1.022373  1.995306   \n",
       "Valente  0.373994  3.152764  0.771258 -2.766039 -1.500564  2.224121  0.000000   \n",
       "\n",
       "              sea     stand     ivory      made     could    cannot     loved  \\\n",
       "Machado -2.147025 -2.150524 -2.157837 -2.183235 -2.241718 -2.258107 -2.323451   \n",
       "Swirsky -0.497472  0.773474  3.545670 -0.436078  0.000000  2.052546  0.851641   \n",
       "Valente  2.368000  0.818884 -1.683480  2.347955  1.897286  0.217676  0.713571   \n",
       "\n",
       "            lions       big      must      lion      rose  \n",
       "Machado -2.425863 -2.496075 -2.536800 -3.134724 -4.800011  \n",
       "Swirsky -3.271085 -1.885389  3.222733 -3.567136  7.166028  \n",
       "Valente  4.483299  3.963153 -1.024925  5.254740 -4.342088  \n",
       "\n",
       "[3 rows x 7822 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rose</th>\n",
       "      <th>d</th>\n",
       "      <th>love</th>\n",
       "      <th>ivory</th>\n",
       "      <th>must</th>\n",
       "      <th>bird</th>\n",
       "      <th>him</th>\n",
       "      <th>across</th>\n",
       "      <th>wine</th>\n",
       "      <th>moment</th>\n",
       "      <th>gods</th>\n",
       "      <th>pedestal</th>\n",
       "      <th>until</th>\n",
       "      <th>felt</th>\n",
       "      <th>okay</th>\n",
       "      <th>will</th>\n",
       "      <th>he</th>\n",
       "      <th>beauty</th>\n",
       "      <th>laughter</th>\n",
       "      <th>statue</th>\n",
       "      <th>teenager</th>\n",
       "      <th>lambs</th>\n",
       "      <th>cold</th>\n",
       "      <th>take</th>\n",
       "      <th>cannot</th>\n",
       "      <th>roses</th>\n",
       "      <th>his</th>\n",
       "      <th>would</th>\n",
       "      <th>robot</th>\n",
       "      <th>seemed</th>\n",
       "      <th>hammer</th>\n",
       "      <th>driver</th>\n",
       "      <th>bronze</th>\n",
       "      <th>threw</th>\n",
       "      <th>passion</th>\n",
       "      <th>sand</th>\n",
       "      <th>sun</th>\n",
       "      <th>brain</th>\n",
       "      <th>spear</th>\n",
       "      <th>consciousness</th>\n",
       "      <th>continue</th>\n",
       "      <th>purpose</th>\n",
       "      <th>men</th>\n",
       "      <th>return</th>\n",
       "      <th>toward</th>\n",
       "      <th>mazatlan</th>\n",
       "      <th>quietly</th>\n",
       "      <th>mortal</th>\n",
       "      <th>walking</th>\n",
       "      <th>bandages</th>\n",
       "      <th>...</th>\n",
       "      <th>dreambody</th>\n",
       "      <th>difference</th>\n",
       "      <th>well</th>\n",
       "      <th>smallgod</th>\n",
       "      <th>come</th>\n",
       "      <th>but</th>\n",
       "      <th>up</th>\n",
       "      <th>stories</th>\n",
       "      <th>parents</th>\n",
       "      <th>steelveldt</th>\n",
       "      <th>inside</th>\n",
       "      <th>who</th>\n",
       "      <th>sister</th>\n",
       "      <th>say</th>\n",
       "      <th>a</th>\n",
       "      <th>dormouse</th>\n",
       "      <th>you</th>\n",
       "      <th>nose</th>\n",
       "      <th>alive</th>\n",
       "      <th>update</th>\n",
       "      <th>please</th>\n",
       "      <th>asks</th>\n",
       "      <th>myself</th>\n",
       "      <th>like</th>\n",
       "      <th>death</th>\n",
       "      <th>big</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>looks</th>\n",
       "      <th>young</th>\n",
       "      <th>name</th>\n",
       "      <th>saw</th>\n",
       "      <th>just</th>\n",
       "      <th>interior</th>\n",
       "      <th>black</th>\n",
       "      <th>son</th>\n",
       "      <th>about</th>\n",
       "      <th>our</th>\n",
       "      <th>it</th>\n",
       "      <th>ribbon</th>\n",
       "      <th>story</th>\n",
       "      <th>very</th>\n",
       "      <th>one</th>\n",
       "      <th>mother</th>\n",
       "      <th>and</th>\n",
       "      <th>lions</th>\n",
       "      <th>lion</th>\n",
       "      <th>we</th>\n",
       "      <th>i</th>\n",
       "      <th>says</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>-4.800011</td>\n",
       "      <td>-1.638078</td>\n",
       "      <td>-1.898607</td>\n",
       "      <td>-2.157837</td>\n",
       "      <td>-2.536800</td>\n",
       "      <td>-2.053991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.149282</td>\n",
       "      <td>-1.063426</td>\n",
       "      <td>-0.944502</td>\n",
       "      <td>-0.889829</td>\n",
       "      <td>-1.029518</td>\n",
       "      <td>-0.801486</td>\n",
       "      <td>-0.673210</td>\n",
       "      <td>-0.952313</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>1.054713</td>\n",
       "      <td>-0.485962</td>\n",
       "      <td>-0.654795</td>\n",
       "      <td>-0.969693</td>\n",
       "      <td>-0.754045</td>\n",
       "      <td>-1.226958</td>\n",
       "      <td>-0.009398</td>\n",
       "      <td>-1.217234</td>\n",
       "      <td>-2.258107</td>\n",
       "      <td>-0.544269</td>\n",
       "      <td>-0.874503</td>\n",
       "      <td>-1.167863</td>\n",
       "      <td>-2.139092</td>\n",
       "      <td>-1.096373</td>\n",
       "      <td>-1.000882</td>\n",
       "      <td>-0.826744</td>\n",
       "      <td>-0.660832</td>\n",
       "      <td>-0.720753</td>\n",
       "      <td>-0.830098</td>\n",
       "      <td>-1.012389</td>\n",
       "      <td>-1.385792</td>\n",
       "      <td>-1.149069</td>\n",
       "      <td>-0.763239</td>\n",
       "      <td>-0.780662</td>\n",
       "      <td>-1.129161</td>\n",
       "      <td>-0.431125</td>\n",
       "      <td>-1.431624</td>\n",
       "      <td>-0.305848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.862052</td>\n",
       "      <td>-0.576280</td>\n",
       "      <td>-0.748168</td>\n",
       "      <td>-0.612711</td>\n",
       "      <td>-0.647043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976668</td>\n",
       "      <td>-1.256514</td>\n",
       "      <td>-0.050650</td>\n",
       "      <td>-1.324618</td>\n",
       "      <td>1.197177</td>\n",
       "      <td>1.370729</td>\n",
       "      <td>1.177313</td>\n",
       "      <td>0.444432</td>\n",
       "      <td>3.919196</td>\n",
       "      <td>-1.517608</td>\n",
       "      <td>-1.612971</td>\n",
       "      <td>1.68683</td>\n",
       "      <td>2.343317</td>\n",
       "      <td>1.824046</td>\n",
       "      <td>1.084285</td>\n",
       "      <td>-1.779758</td>\n",
       "      <td>1.583886</td>\n",
       "      <td>0.810624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326090</td>\n",
       "      <td>2.626904</td>\n",
       "      <td>2.075203</td>\n",
       "      <td>-0.730685</td>\n",
       "      <td>0.964073</td>\n",
       "      <td>0.626956</td>\n",
       "      <td>-2.496075</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>0.940510</td>\n",
       "      <td>0.464680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.056416</td>\n",
       "      <td>2.007402</td>\n",
       "      <td>-1.158041</td>\n",
       "      <td>-0.799293</td>\n",
       "      <td>3.157463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.601907</td>\n",
       "      <td>0.425971</td>\n",
       "      <td>3.974845</td>\n",
       "      <td>0.696054</td>\n",
       "      <td>1.145041</td>\n",
       "      <td>0.646714</td>\n",
       "      <td>-0.500906</td>\n",
       "      <td>0.849723</td>\n",
       "      <td>-2.425863</td>\n",
       "      <td>-3.134724</td>\n",
       "      <td>0.883847</td>\n",
       "      <td>3.605472</td>\n",
       "      <td>2.950417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>7.166028</td>\n",
       "      <td>4.845712</td>\n",
       "      <td>4.176348</td>\n",
       "      <td>3.545670</td>\n",
       "      <td>3.222733</td>\n",
       "      <td>3.155047</td>\n",
       "      <td>3.107196</td>\n",
       "      <td>2.841114</td>\n",
       "      <td>2.821888</td>\n",
       "      <td>2.734865</td>\n",
       "      <td>2.697297</td>\n",
       "      <td>2.670063</td>\n",
       "      <td>2.626999</td>\n",
       "      <td>2.588902</td>\n",
       "      <td>2.529076</td>\n",
       "      <td>2.434787</td>\n",
       "      <td>2.422747</td>\n",
       "      <td>2.317191</td>\n",
       "      <td>2.268364</td>\n",
       "      <td>2.267589</td>\n",
       "      <td>2.258900</td>\n",
       "      <td>2.258662</td>\n",
       "      <td>2.091799</td>\n",
       "      <td>2.076932</td>\n",
       "      <td>2.052546</td>\n",
       "      <td>2.047268</td>\n",
       "      <td>2.043973</td>\n",
       "      <td>2.015196</td>\n",
       "      <td>1.995306</td>\n",
       "      <td>1.988395</td>\n",
       "      <td>1.968934</td>\n",
       "      <td>1.917505</td>\n",
       "      <td>1.916595</td>\n",
       "      <td>1.905265</td>\n",
       "      <td>1.871964</td>\n",
       "      <td>1.868814</td>\n",
       "      <td>1.804851</td>\n",
       "      <td>1.798841</td>\n",
       "      <td>1.797448</td>\n",
       "      <td>1.780729</td>\n",
       "      <td>1.778599</td>\n",
       "      <td>1.768067</td>\n",
       "      <td>1.743821</td>\n",
       "      <td>1.712986</td>\n",
       "      <td>1.707723</td>\n",
       "      <td>1.702375</td>\n",
       "      <td>1.697403</td>\n",
       "      <td>1.693946</td>\n",
       "      <td>1.678482</td>\n",
       "      <td>1.668825</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.599526</td>\n",
       "      <td>-1.611960</td>\n",
       "      <td>-1.616986</td>\n",
       "      <td>-1.628849</td>\n",
       "      <td>-1.644763</td>\n",
       "      <td>-1.670280</td>\n",
       "      <td>-1.670739</td>\n",
       "      <td>-1.691546</td>\n",
       "      <td>-1.703086</td>\n",
       "      <td>-1.722126</td>\n",
       "      <td>-1.741765</td>\n",
       "      <td>-1.75578</td>\n",
       "      <td>-1.758987</td>\n",
       "      <td>-1.762000</td>\n",
       "      <td>-1.791219</td>\n",
       "      <td>-1.797952</td>\n",
       "      <td>-1.809811</td>\n",
       "      <td>-1.829251</td>\n",
       "      <td>-1.831024</td>\n",
       "      <td>-1.831552</td>\n",
       "      <td>-1.850840</td>\n",
       "      <td>-1.851282</td>\n",
       "      <td>-1.852187</td>\n",
       "      <td>-1.867050</td>\n",
       "      <td>-1.873065</td>\n",
       "      <td>-1.885389</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-1.900736</td>\n",
       "      <td>-1.926103</td>\n",
       "      <td>-1.973165</td>\n",
       "      <td>-1.975921</td>\n",
       "      <td>-1.989908</td>\n",
       "      <td>-2.006609</td>\n",
       "      <td>-2.014176</td>\n",
       "      <td>-2.060466</td>\n",
       "      <td>-2.094507</td>\n",
       "      <td>-2.166231</td>\n",
       "      <td>-2.231060</td>\n",
       "      <td>-2.268152</td>\n",
       "      <td>-2.277151</td>\n",
       "      <td>-2.482947</td>\n",
       "      <td>-2.590397</td>\n",
       "      <td>-2.828272</td>\n",
       "      <td>-2.940672</td>\n",
       "      <td>-3.271085</td>\n",
       "      <td>-3.567136</td>\n",
       "      <td>-3.667850</td>\n",
       "      <td>-4.161711</td>\n",
       "      <td>-4.162776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>-4.342088</td>\n",
       "      <td>-3.646938</td>\n",
       "      <td>-2.766039</td>\n",
       "      <td>-1.683480</td>\n",
       "      <td>-1.024925</td>\n",
       "      <td>-1.500564</td>\n",
       "      <td>-3.457758</td>\n",
       "      <td>-1.747252</td>\n",
       "      <td>-1.690515</td>\n",
       "      <td>-1.679198</td>\n",
       "      <td>-2.030393</td>\n",
       "      <td>-1.551509</td>\n",
       "      <td>-1.762763</td>\n",
       "      <td>-2.149647</td>\n",
       "      <td>-1.951754</td>\n",
       "      <td>-3.305912</td>\n",
       "      <td>-4.089746</td>\n",
       "      <td>-1.700057</td>\n",
       "      <td>-1.653805</td>\n",
       "      <td>-1.134595</td>\n",
       "      <td>-1.396031</td>\n",
       "      <td>-0.891518</td>\n",
       "      <td>-1.866966</td>\n",
       "      <td>-0.723243</td>\n",
       "      <td>0.217676</td>\n",
       "      <td>-1.343261</td>\n",
       "      <td>-1.747176</td>\n",
       "      <td>-0.531071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.652594</td>\n",
       "      <td>-1.059578</td>\n",
       "      <td>-1.179875</td>\n",
       "      <td>-1.241791</td>\n",
       "      <td>-0.982550</td>\n",
       "      <td>-0.970157</td>\n",
       "      <td>-0.747204</td>\n",
       "      <td>-0.530921</td>\n",
       "      <td>-0.893931</td>\n",
       "      <td>-0.912117</td>\n",
       "      <td>-0.975156</td>\n",
       "      <td>-0.514112</td>\n",
       "      <td>-1.020341</td>\n",
       "      <td>-0.125701</td>\n",
       "      <td>-1.343869</td>\n",
       "      <td>-1.818563</td>\n",
       "      <td>-0.909062</td>\n",
       "      <td>-1.053944</td>\n",
       "      <td>-0.966806</td>\n",
       "      <td>-0.769849</td>\n",
       "      <td>-0.986855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.477864</td>\n",
       "      <td>3.065357</td>\n",
       "      <td>1.552152</td>\n",
       "      <td>2.631435</td>\n",
       "      <td>0.386172</td>\n",
       "      <td>0.207010</td>\n",
       "      <td>0.832278</td>\n",
       "      <td>0.817955</td>\n",
       "      <td>-2.042637</td>\n",
       "      <td>2.962847</td>\n",
       "      <td>2.683822</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.758352</td>\n",
       "      <td>-0.370593</td>\n",
       "      <td>0.323204</td>\n",
       "      <td>3.152764</td>\n",
       "      <td>0.780458</td>\n",
       "      <td>0.941692</td>\n",
       "      <td>1.563206</td>\n",
       "      <td>0.293531</td>\n",
       "      <td>-1.194753</td>\n",
       "      <td>-0.112739</td>\n",
       "      <td>2.104697</td>\n",
       "      <td>0.807064</td>\n",
       "      <td>0.883705</td>\n",
       "      <td>3.963153</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>0.422773</td>\n",
       "      <td>1.145264</td>\n",
       "      <td>1.673622</td>\n",
       "      <td>0.581567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.898089</td>\n",
       "      <td>2.629202</td>\n",
       "      <td>-1.409897</td>\n",
       "      <td>1.469220</td>\n",
       "      <td>0.269128</td>\n",
       "      <td>1.536598</td>\n",
       "      <td>-2.164409</td>\n",
       "      <td>0.947326</td>\n",
       "      <td>0.986430</td>\n",
       "      <td>1.782445</td>\n",
       "      <td>2.858088</td>\n",
       "      <td>1.823031</td>\n",
       "      <td>4.483299</td>\n",
       "      <td>5.254740</td>\n",
       "      <td>2.207598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rose         d      love     ivory      must      bird       him  \\\n",
       "Machado -4.800011 -1.638078 -1.898607 -2.157837 -2.536800 -2.053991  0.000000   \n",
       "Swirsky  7.166028  4.845712  4.176348  3.545670  3.222733  3.155047  3.107196   \n",
       "Valente -4.342088 -3.646938 -2.766039 -1.683480 -1.024925 -1.500564 -3.457758   \n",
       "\n",
       "           across      wine    moment      gods  pedestal     until      felt  \\\n",
       "Machado -1.149282 -1.063426 -0.944502 -0.889829 -1.029518 -0.801486 -0.673210   \n",
       "Swirsky  2.841114  2.821888  2.734865  2.697297  2.670063  2.626999  2.588902   \n",
       "Valente -1.747252 -1.690515 -1.679198 -2.030393 -1.551509 -1.762763 -2.149647   \n",
       "\n",
       "             okay      will        he    beauty  laughter    statue  teenager  \\\n",
       "Machado -0.952313  0.814867  1.054713 -0.485962 -0.654795 -0.969693 -0.754045   \n",
       "Swirsky  2.529076  2.434787  2.422747  2.317191  2.268364  2.267589  2.258900   \n",
       "Valente -1.951754 -3.305912 -4.089746 -1.700057 -1.653805 -1.134595 -1.396031   \n",
       "\n",
       "            lambs      cold      take    cannot     roses       his     would  \\\n",
       "Machado -1.226958 -0.009398 -1.217234 -2.258107 -0.544269 -0.874503 -1.167863   \n",
       "Swirsky  2.258662  2.091799  2.076932  2.052546  2.047268  2.043973  2.015196   \n",
       "Valente -0.891518 -1.866966 -0.723243  0.217676 -1.343261 -1.747176 -0.531071   \n",
       "\n",
       "            robot    seemed    hammer    driver    bronze     threw   passion  \\\n",
       "Machado -2.139092 -1.096373 -1.000882 -0.826744 -0.660832 -0.720753 -0.830098   \n",
       "Swirsky  1.995306  1.988395  1.968934  1.917505  1.916595  1.905265  1.871964   \n",
       "Valente  0.000000 -0.652594 -1.059578 -1.179875 -1.241791 -0.982550 -0.970157   \n",
       "\n",
       "             sand       sun     brain     spear  consciousness  continue  \\\n",
       "Machado -1.012389 -1.385792 -1.149069 -0.763239      -0.780662 -1.129161   \n",
       "Swirsky  1.868814  1.804851  1.798841  1.797448       1.780729  1.778599   \n",
       "Valente -0.747204 -0.530921 -0.893931 -0.912117      -0.975156 -0.514112   \n",
       "\n",
       "          purpose       men    return    toward  mazatlan   quietly    mortal  \\\n",
       "Machado -0.431125 -1.431624 -0.305848  0.000000 -0.862052 -0.576280 -0.748168   \n",
       "Swirsky  1.768067  1.743821  1.712986  1.707723  1.702375  1.697403  1.693946   \n",
       "Valente -1.020341 -0.125701 -1.343869 -1.818563 -0.909062 -1.053944 -0.966806   \n",
       "\n",
       "          walking  bandages    ...     dreambody  difference      well  \\\n",
       "Machado -0.612711 -0.647043    ...     -0.976668   -1.256514 -0.050650   \n",
       "Swirsky  1.678482  1.668825    ...     -1.599526   -1.611960 -1.616986   \n",
       "Valente -0.769849 -0.986855    ...      2.477864    3.065357  1.552152   \n",
       "\n",
       "         smallgod      come       but        up   stories   parents  \\\n",
       "Machado -1.324618  1.197177  1.370729  1.177313  0.444432  3.919196   \n",
       "Swirsky -1.628849 -1.644763 -1.670280 -1.670739 -1.691546 -1.703086   \n",
       "Valente  2.631435  0.386172  0.207010  0.832278  0.817955 -2.042637   \n",
       "\n",
       "         steelveldt    inside      who    sister       say         a  \\\n",
       "Machado   -1.517608 -1.612971  1.68683  2.343317  1.824046  1.084285   \n",
       "Swirsky   -1.722126 -1.741765 -1.75578 -1.758987 -1.762000 -1.791219   \n",
       "Valente    2.962847  2.683822  0.00000 -0.758352 -0.370593  0.323204   \n",
       "\n",
       "         dormouse       you      nose     alive    update    please      asks  \\\n",
       "Machado -1.779758  1.583886  0.810624  0.000000  1.326090  2.626904  2.075203   \n",
       "Swirsky -1.797952 -1.809811 -1.829251 -1.831024 -1.831552 -1.850840 -1.851282   \n",
       "Valente  3.152764  0.780458  0.941692  1.563206  0.293531 -1.194753 -0.112739   \n",
       "\n",
       "           myself      like     death       big      hole  watering     looks  \\\n",
       "Machado -0.730685  0.964073  0.626956 -2.496075 -1.433109 -1.433109  0.940510   \n",
       "Swirsky -1.852187 -1.867050 -1.873065 -1.885389 -1.886024 -1.886024 -1.900736   \n",
       "Valente  2.104697  0.807064  0.883705  3.963153  2.714336  2.714336  0.422773   \n",
       "\n",
       "            young      name       saw      just  interior     black       son  \\\n",
       "Machado  0.464680  0.000000  1.056416  2.007402 -1.158041 -0.799293  3.157463   \n",
       "Swirsky -1.926103 -1.973165 -1.975921 -1.989908 -2.006609 -2.014176 -2.060466   \n",
       "Valente  1.145264  1.673622  0.581567  0.000000  2.898089  2.629202 -1.409897   \n",
       "\n",
       "            about       our        it    ribbon     story      very       one  \\\n",
       "Machado  0.000000  1.601907  0.425971  3.974845  0.696054  1.145041  0.646714   \n",
       "Swirsky -2.094507 -2.166231 -2.231060 -2.268152 -2.277151 -2.482947 -2.590397   \n",
       "Valente  1.469220  0.269128  1.536598 -2.164409  0.947326  0.986430  1.782445   \n",
       "\n",
       "           mother       and     lions      lion        we         i      says  \n",
       "Machado -0.500906  0.849723 -2.425863 -3.134724  0.883847  3.605472  2.950417  \n",
       "Swirsky -2.828272 -2.940672 -3.271085 -3.567136 -3.667850 -4.161711 -4.162776  \n",
       "Valente  2.858088  1.823031  4.483299  5.254740  2.207598  0.000000  0.292788  \n",
       "\n",
       "[3 rows x 7822 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lion</th>\n",
       "      <th>lions</th>\n",
       "      <th>big</th>\n",
       "      <th>dormouse</th>\n",
       "      <th>difference</th>\n",
       "      <th>steelveldt</th>\n",
       "      <th>interior</th>\n",
       "      <th>mother</th>\n",
       "      <th>wants</th>\n",
       "      <th>princess</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>inside</th>\n",
       "      <th>smallgod</th>\n",
       "      <th>black</th>\n",
       "      <th>uplink</th>\n",
       "      <th>machine</th>\n",
       "      <th>sludge</th>\n",
       "      <th>lonely</th>\n",
       "      <th>dreambody</th>\n",
       "      <th>sea</th>\n",
       "      <th>test</th>\n",
       "      <th>made</th>\n",
       "      <th>blue</th>\n",
       "      <th>quite</th>\n",
       "      <th>old</th>\n",
       "      <th>called</th>\n",
       "      <th>we</th>\n",
       "      <th>code</th>\n",
       "      <th>means</th>\n",
       "      <th>sapphire</th>\n",
       "      <th>several</th>\n",
       "      <th>prince</th>\n",
       "      <th>humanity</th>\n",
       "      <th>learn</th>\n",
       "      <th>of</th>\n",
       "      <th>myself</th>\n",
       "      <th>tammuz</th>\n",
       "      <th>jewel</th>\n",
       "      <th>feels</th>\n",
       "      <th>smallgods</th>\n",
       "      <th>show</th>\n",
       "      <th>some</th>\n",
       "      <th>system</th>\n",
       "      <th>jungle</th>\n",
       "      <th>most</th>\n",
       "      <th>copied</th>\n",
       "      <th>wanted</th>\n",
       "      <th>did</th>\n",
       "      <th>male</th>\n",
       "      <th>...</th>\n",
       "      <th>students</th>\n",
       "      <th>sisters</th>\n",
       "      <th>laughter</th>\n",
       "      <th>another</th>\n",
       "      <th>moment</th>\n",
       "      <th>ivory</th>\n",
       "      <th>wine</th>\n",
       "      <th>here</th>\n",
       "      <th>beauty</th>\n",
       "      <th>got</th>\n",
       "      <th>cut</th>\n",
       "      <th>may</th>\n",
       "      <th>nothing</th>\n",
       "      <th>hot</th>\n",
       "      <th>his</th>\n",
       "      <th>across</th>\n",
       "      <th>t</th>\n",
       "      <th>see</th>\n",
       "      <th>until</th>\n",
       "      <th>front</th>\n",
       "      <th>toward</th>\n",
       "      <th>beneath</th>\n",
       "      <th>cold</th>\n",
       "      <th>why</th>\n",
       "      <th>from</th>\n",
       "      <th>then</th>\n",
       "      <th>okay</th>\n",
       "      <th>hear</th>\n",
       "      <th>room</th>\n",
       "      <th>doctor</th>\n",
       "      <th>gods</th>\n",
       "      <th>parents</th>\n",
       "      <th>boy</th>\n",
       "      <th>my</th>\n",
       "      <th>felt</th>\n",
       "      <th>ribbon</th>\n",
       "      <th>were</th>\n",
       "      <th>going</th>\n",
       "      <th>cal</th>\n",
       "      <th>husband</th>\n",
       "      <th>against</th>\n",
       "      <th>away</th>\n",
       "      <th>she</th>\n",
       "      <th>love</th>\n",
       "      <th>will</th>\n",
       "      <th>him</th>\n",
       "      <th>woman</th>\n",
       "      <th>d</th>\n",
       "      <th>he</th>\n",
       "      <th>rose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>-3.134724</td>\n",
       "      <td>-2.425863</td>\n",
       "      <td>-2.496075</td>\n",
       "      <td>-1.779758</td>\n",
       "      <td>-1.256514</td>\n",
       "      <td>-1.517608</td>\n",
       "      <td>-1.158041</td>\n",
       "      <td>-0.500906</td>\n",
       "      <td>-1.724241</td>\n",
       "      <td>-1.376662</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>-1.433109</td>\n",
       "      <td>-1.612971</td>\n",
       "      <td>-1.324618</td>\n",
       "      <td>-0.799293</td>\n",
       "      <td>-1.614615</td>\n",
       "      <td>-1.518525</td>\n",
       "      <td>-1.086755</td>\n",
       "      <td>-1.622697</td>\n",
       "      <td>-0.976668</td>\n",
       "      <td>-2.147025</td>\n",
       "      <td>-1.260305</td>\n",
       "      <td>-2.183235</td>\n",
       "      <td>-1.742081</td>\n",
       "      <td>-1.389133</td>\n",
       "      <td>-1.225735</td>\n",
       "      <td>-2.135795</td>\n",
       "      <td>0.883847</td>\n",
       "      <td>-1.257507</td>\n",
       "      <td>-1.110390</td>\n",
       "      <td>-1.298553</td>\n",
       "      <td>-1.156544</td>\n",
       "      <td>-0.753722</td>\n",
       "      <td>-1.093096</td>\n",
       "      <td>-1.033697</td>\n",
       "      <td>-0.933179</td>\n",
       "      <td>-0.730685</td>\n",
       "      <td>-1.103205</td>\n",
       "      <td>-1.148511</td>\n",
       "      <td>-1.005207</td>\n",
       "      <td>-0.877760</td>\n",
       "      <td>-0.798576</td>\n",
       "      <td>-0.732019</td>\n",
       "      <td>-1.073361</td>\n",
       "      <td>-0.845074</td>\n",
       "      <td>-0.876608</td>\n",
       "      <td>-0.609451</td>\n",
       "      <td>-1.210241</td>\n",
       "      <td>-0.903814</td>\n",
       "      <td>-0.623100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.541305</td>\n",
       "      <td>1.057233</td>\n",
       "      <td>-0.654795</td>\n",
       "      <td>0.805372</td>\n",
       "      <td>-0.944502</td>\n",
       "      <td>-2.157837</td>\n",
       "      <td>-1.063426</td>\n",
       "      <td>2.311473</td>\n",
       "      <td>-0.485962</td>\n",
       "      <td>0.630453</td>\n",
       "      <td>1.064582</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564762</td>\n",
       "      <td>-0.874503</td>\n",
       "      <td>-1.149282</td>\n",
       "      <td>1.797667</td>\n",
       "      <td>1.793311</td>\n",
       "      <td>-0.801486</td>\n",
       "      <td>1.012274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.179760</td>\n",
       "      <td>-0.009398</td>\n",
       "      <td>2.598042</td>\n",
       "      <td>1.049794</td>\n",
       "      <td>1.832422</td>\n",
       "      <td>-0.952313</td>\n",
       "      <td>2.228633</td>\n",
       "      <td>2.244174</td>\n",
       "      <td>3.496119</td>\n",
       "      <td>-0.889829</td>\n",
       "      <td>3.919196</td>\n",
       "      <td>2.058032</td>\n",
       "      <td>3.364507</td>\n",
       "      <td>-0.673210</td>\n",
       "      <td>3.974845</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>3.256018</td>\n",
       "      <td>3.580084</td>\n",
       "      <td>2.476677</td>\n",
       "      <td>0.855733</td>\n",
       "      <td>1.516958</td>\n",
       "      <td>1.921005</td>\n",
       "      <td>-1.898607</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.846457</td>\n",
       "      <td>-1.638078</td>\n",
       "      <td>1.054713</td>\n",
       "      <td>-4.800011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>-3.567136</td>\n",
       "      <td>-3.271085</td>\n",
       "      <td>-1.885389</td>\n",
       "      <td>-1.797952</td>\n",
       "      <td>-1.611960</td>\n",
       "      <td>-1.722126</td>\n",
       "      <td>-2.006609</td>\n",
       "      <td>-2.828272</td>\n",
       "      <td>-1.196232</td>\n",
       "      <td>-1.536956</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-1.886024</td>\n",
       "      <td>-1.741765</td>\n",
       "      <td>-1.628849</td>\n",
       "      <td>-2.014176</td>\n",
       "      <td>-1.307520</td>\n",
       "      <td>-1.384145</td>\n",
       "      <td>-1.358855</td>\n",
       "      <td>-0.991167</td>\n",
       "      <td>-1.599526</td>\n",
       "      <td>-0.497472</td>\n",
       "      <td>-1.125113</td>\n",
       "      <td>-0.436078</td>\n",
       "      <td>-1.033375</td>\n",
       "      <td>-0.868509</td>\n",
       "      <td>-1.049325</td>\n",
       "      <td>-1.022373</td>\n",
       "      <td>-3.667850</td>\n",
       "      <td>-1.401875</td>\n",
       "      <td>-1.232368</td>\n",
       "      <td>-1.070866</td>\n",
       "      <td>-1.022382</td>\n",
       "      <td>-1.380987</td>\n",
       "      <td>-1.355782</td>\n",
       "      <td>-1.195811</td>\n",
       "      <td>-1.587750</td>\n",
       "      <td>-1.852187</td>\n",
       "      <td>-1.171124</td>\n",
       "      <td>-1.156108</td>\n",
       "      <td>-1.002455</td>\n",
       "      <td>-1.402288</td>\n",
       "      <td>-1.594509</td>\n",
       "      <td>-1.519273</td>\n",
       "      <td>-1.008076</td>\n",
       "      <td>-1.166433</td>\n",
       "      <td>-1.163759</td>\n",
       "      <td>-1.296567</td>\n",
       "      <td>-0.943730</td>\n",
       "      <td>-1.514461</td>\n",
       "      <td>-1.156948</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.004251</td>\n",
       "      <td>0.319009</td>\n",
       "      <td>2.268364</td>\n",
       "      <td>0.795158</td>\n",
       "      <td>2.734865</td>\n",
       "      <td>3.545670</td>\n",
       "      <td>2.821888</td>\n",
       "      <td>-0.530247</td>\n",
       "      <td>2.317191</td>\n",
       "      <td>1.103186</td>\n",
       "      <td>0.445304</td>\n",
       "      <td>1.347083</td>\n",
       "      <td>1.527255</td>\n",
       "      <td>1.026050</td>\n",
       "      <td>2.043973</td>\n",
       "      <td>2.841114</td>\n",
       "      <td>-0.387161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.626999</td>\n",
       "      <td>0.663479</td>\n",
       "      <td>1.707723</td>\n",
       "      <td>-0.173321</td>\n",
       "      <td>2.091799</td>\n",
       "      <td>-0.782955</td>\n",
       "      <td>0.871066</td>\n",
       "      <td>-0.243778</td>\n",
       "      <td>2.529076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.163792</td>\n",
       "      <td>-1.587053</td>\n",
       "      <td>2.697297</td>\n",
       "      <td>-1.703086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.104871</td>\n",
       "      <td>2.588902</td>\n",
       "      <td>-2.268152</td>\n",
       "      <td>1.555509</td>\n",
       "      <td>-1.348633</td>\n",
       "      <td>-1.451850</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>1.343608</td>\n",
       "      <td>0.842833</td>\n",
       "      <td>0.648838</td>\n",
       "      <td>4.176348</td>\n",
       "      <td>2.434787</td>\n",
       "      <td>3.107196</td>\n",
       "      <td>0.327939</td>\n",
       "      <td>4.845712</td>\n",
       "      <td>2.422747</td>\n",
       "      <td>7.166028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>5.254740</td>\n",
       "      <td>4.483299</td>\n",
       "      <td>3.963153</td>\n",
       "      <td>3.152764</td>\n",
       "      <td>3.065357</td>\n",
       "      <td>2.962847</td>\n",
       "      <td>2.898089</td>\n",
       "      <td>2.858088</td>\n",
       "      <td>2.850734</td>\n",
       "      <td>2.748941</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>2.714336</td>\n",
       "      <td>2.683822</td>\n",
       "      <td>2.631435</td>\n",
       "      <td>2.629202</td>\n",
       "      <td>2.617961</td>\n",
       "      <td>2.585487</td>\n",
       "      <td>2.514743</td>\n",
       "      <td>2.482070</td>\n",
       "      <td>2.477864</td>\n",
       "      <td>2.368000</td>\n",
       "      <td>2.363182</td>\n",
       "      <td>2.347955</td>\n",
       "      <td>2.330612</td>\n",
       "      <td>2.236426</td>\n",
       "      <td>2.235526</td>\n",
       "      <td>2.224121</td>\n",
       "      <td>2.207598</td>\n",
       "      <td>2.205381</td>\n",
       "      <td>2.197308</td>\n",
       "      <td>2.194523</td>\n",
       "      <td>2.186894</td>\n",
       "      <td>2.178236</td>\n",
       "      <td>2.167852</td>\n",
       "      <td>2.131860</td>\n",
       "      <td>2.128791</td>\n",
       "      <td>2.104697</td>\n",
       "      <td>2.085912</td>\n",
       "      <td>2.084957</td>\n",
       "      <td>2.083078</td>\n",
       "      <td>2.079016</td>\n",
       "      <td>2.017507</td>\n",
       "      <td>2.000283</td>\n",
       "      <td>1.999229</td>\n",
       "      <td>1.992868</td>\n",
       "      <td>1.965185</td>\n",
       "      <td>1.962998</td>\n",
       "      <td>1.958936</td>\n",
       "      <td>1.946444</td>\n",
       "      <td>1.897625</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.582846</td>\n",
       "      <td>-1.638424</td>\n",
       "      <td>-1.653805</td>\n",
       "      <td>-1.678187</td>\n",
       "      <td>-1.679198</td>\n",
       "      <td>-1.683480</td>\n",
       "      <td>-1.690515</td>\n",
       "      <td>-1.698537</td>\n",
       "      <td>-1.700057</td>\n",
       "      <td>-1.709760</td>\n",
       "      <td>-1.720566</td>\n",
       "      <td>-1.731631</td>\n",
       "      <td>-1.732480</td>\n",
       "      <td>-1.741876</td>\n",
       "      <td>-1.747176</td>\n",
       "      <td>-1.747252</td>\n",
       "      <td>-1.757788</td>\n",
       "      <td>-1.759752</td>\n",
       "      <td>-1.762763</td>\n",
       "      <td>-1.765728</td>\n",
       "      <td>-1.818563</td>\n",
       "      <td>-1.862371</td>\n",
       "      <td>-1.866966</td>\n",
       "      <td>-1.886176</td>\n",
       "      <td>-1.909354</td>\n",
       "      <td>-1.916141</td>\n",
       "      <td>-1.951754</td>\n",
       "      <td>-1.958914</td>\n",
       "      <td>-1.970271</td>\n",
       "      <td>-2.029777</td>\n",
       "      <td>-2.030393</td>\n",
       "      <td>-2.042637</td>\n",
       "      <td>-2.125012</td>\n",
       "      <td>-2.139792</td>\n",
       "      <td>-2.149647</td>\n",
       "      <td>-2.164409</td>\n",
       "      <td>-2.164667</td>\n",
       "      <td>-2.204059</td>\n",
       "      <td>-2.314492</td>\n",
       "      <td>-2.332120</td>\n",
       "      <td>-2.411777</td>\n",
       "      <td>-2.478601</td>\n",
       "      <td>-2.523657</td>\n",
       "      <td>-2.766039</td>\n",
       "      <td>-3.305912</td>\n",
       "      <td>-3.457758</td>\n",
       "      <td>-3.531082</td>\n",
       "      <td>-3.646938</td>\n",
       "      <td>-4.089746</td>\n",
       "      <td>-4.342088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lion     lions       big  dormouse  difference  steelveldt  \\\n",
       "Machado -3.134724 -2.425863 -2.496075 -1.779758   -1.256514   -1.517608   \n",
       "Swirsky -3.567136 -3.271085 -1.885389 -1.797952   -1.611960   -1.722126   \n",
       "Valente  5.254740  4.483299  3.963153  3.152764    3.065357    2.962847   \n",
       "\n",
       "         interior    mother     wants  princess      hole  watering    inside  \\\n",
       "Machado -1.158041 -0.500906 -1.724241 -1.376662 -1.433109 -1.433109 -1.612971   \n",
       "Swirsky -2.006609 -2.828272 -1.196232 -1.536956 -1.886024 -1.886024 -1.741765   \n",
       "Valente  2.898089  2.858088  2.850734  2.748941  2.714336  2.714336  2.683822   \n",
       "\n",
       "         smallgod     black    uplink   machine    sludge    lonely  \\\n",
       "Machado -1.324618 -0.799293 -1.614615 -1.518525 -1.086755 -1.622697   \n",
       "Swirsky -1.628849 -2.014176 -1.307520 -1.384145 -1.358855 -0.991167   \n",
       "Valente  2.631435  2.629202  2.617961  2.585487  2.514743  2.482070   \n",
       "\n",
       "         dreambody       sea      test      made      blue     quite  \\\n",
       "Machado  -0.976668 -2.147025 -1.260305 -2.183235 -1.742081 -1.389133   \n",
       "Swirsky  -1.599526 -0.497472 -1.125113 -0.436078 -1.033375 -0.868509   \n",
       "Valente   2.477864  2.368000  2.363182  2.347955  2.330612  2.236426   \n",
       "\n",
       "              old    called        we      code     means  sapphire   several  \\\n",
       "Machado -1.225735 -2.135795  0.883847 -1.257507 -1.110390 -1.298553 -1.156544   \n",
       "Swirsky -1.049325 -1.022373 -3.667850 -1.401875 -1.232368 -1.070866 -1.022382   \n",
       "Valente  2.235526  2.224121  2.207598  2.205381  2.197308  2.194523  2.186894   \n",
       "\n",
       "           prince  humanity     learn        of    myself    tammuz     jewel  \\\n",
       "Machado -0.753722 -1.093096 -1.033697 -0.933179 -0.730685 -1.103205 -1.148511   \n",
       "Swirsky -1.380987 -1.355782 -1.195811 -1.587750 -1.852187 -1.171124 -1.156108   \n",
       "Valente  2.178236  2.167852  2.131860  2.128791  2.104697  2.085912  2.084957   \n",
       "\n",
       "            feels  smallgods      show      some    system    jungle  \\\n",
       "Machado -1.005207  -0.877760 -0.798576 -0.732019 -1.073361 -0.845074   \n",
       "Swirsky -1.002455  -1.402288 -1.594509 -1.519273 -1.008076 -1.166433   \n",
       "Valente  2.083078   2.079016  2.017507  2.000283  1.999229  1.992868   \n",
       "\n",
       "             most    copied    wanted       did      male    ...     students  \\\n",
       "Machado -0.876608 -0.609451 -1.210241 -0.903814 -0.623100    ...     2.541305   \n",
       "Swirsky -1.163759 -1.296567 -0.943730 -1.514461 -1.156948    ...    -1.004251   \n",
       "Valente  1.965185  1.962998  1.958936  1.946444  1.897625    ...    -1.582846   \n",
       "\n",
       "          sisters  laughter   another    moment     ivory      wine      here  \\\n",
       "Machado  1.057233 -0.654795  0.805372 -0.944502 -2.157837 -1.063426  2.311473   \n",
       "Swirsky  0.319009  2.268364  0.795158  2.734865  3.545670  2.821888 -0.530247   \n",
       "Valente -1.638424 -1.653805 -1.678187 -1.679198 -1.683480 -1.690515 -1.698537   \n",
       "\n",
       "           beauty       got       cut       may   nothing       hot       his  \\\n",
       "Machado -0.485962  0.630453  1.064582  0.222878  0.000000  0.564762 -0.874503   \n",
       "Swirsky  2.317191  1.103186  0.445304  1.347083  1.527255  1.026050  2.043973   \n",
       "Valente -1.700057 -1.709760 -1.720566 -1.731631 -1.732480 -1.741876 -1.747176   \n",
       "\n",
       "           across         t       see     until     front    toward   beneath  \\\n",
       "Machado -1.149282  1.797667  1.793311 -0.801486  1.012274  0.000000  2.179760   \n",
       "Swirsky  2.841114 -0.387161  0.000000  2.626999  0.663479  1.707723 -0.173321   \n",
       "Valente -1.747252 -1.757788 -1.759752 -1.762763 -1.765728 -1.818563 -1.862371   \n",
       "\n",
       "             cold       why      from      then      okay      hear      room  \\\n",
       "Machado -0.009398  2.598042  1.049794  1.832422 -0.952313  2.228633  2.244174   \n",
       "Swirsky  2.091799 -0.782955  0.871066 -0.243778  2.529076  0.000000 -0.163792   \n",
       "Valente -1.866966 -1.886176 -1.909354 -1.916141 -1.951754 -1.958914 -1.970271   \n",
       "\n",
       "           doctor      gods   parents       boy        my      felt    ribbon  \\\n",
       "Machado  3.496119 -0.889829  3.919196  2.058032  3.364507 -0.673210  3.974845   \n",
       "Swirsky -1.587053  2.697297 -1.703086  0.000000 -1.104871  2.588902 -2.268152   \n",
       "Valente -2.029777 -2.030393 -2.042637 -2.125012 -2.139792 -2.149647 -2.164409   \n",
       "\n",
       "             were     going       cal   husband   against      away       she  \\\n",
       "Machado  0.962164  3.256018  3.580084  2.476677  0.855733  1.516958  1.921005   \n",
       "Swirsky  1.555509 -1.348633 -1.451850 -0.228277  1.343608  0.842833  0.648838   \n",
       "Valente -2.164667 -2.204059 -2.314492 -2.332120 -2.411777 -2.478601 -2.523657   \n",
       "\n",
       "             love      will       him     woman         d        he      rose  \n",
       "Machado -1.898607  0.814867  0.000000  2.846457 -1.638078  1.054713 -4.800011  \n",
       "Swirsky  4.176348  2.434787  3.107196  0.327939  4.845712  2.422747  7.166028  \n",
       "Valente -2.766039 -3.305912 -3.457758 -3.531082 -3.646938 -4.089746 -4.342088  \n",
       "\n",
       "[3 rows x 7822 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nBest Training Set Score: {:.2%}'.format(grid.cv_results_['mean_train_score'][grid.best_index_]))\n",
    "print('\\nBest Cross-Val Score: {:.2%}'.format(grid.best_score_))\n",
    "\n",
    "print('\\nBest Parameters:\\n')\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('{}: {}'.format(param_name, best_parameters[param_name]))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_score = grid.score(X_test, y_test)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print('\\nTest set score: {:.1%}'.format(test_score))\n",
    "\n",
    "df_test_cm = pd.DataFrame(test_cm, index=grid.classes_, columns=grid.classes_)\n",
    "df_test_cm.index.name = 'Actual Author'\n",
    "df_test_cm.columns.name = 'Predicted Author'\n",
    "display(df_test_cm)\n",
    "\n",
    "feature_list = grid.best_estimator_.named_steps['vect'].get_feature_names()\n",
    "print('\\n{} features'.format(len(feature_list)))\n",
    "feature_coefficients = pd.DataFrame(grid.best_estimator_.steps[-1][1].coef_, columns=feature_list, index=grid.classes_)\n",
    "# columns=feature_list, \n",
    "display(feature_coefficients.sort_values('Machado', ascending=False, axis=1).head(10))\n",
    "display(feature_coefficients.sort_values('Swirsky', ascending=False, axis=1).head(10))\n",
    "display(feature_coefficients.sort_values('Valente', ascending=False, axis=1).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>93.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>65.28</td>\n",
       "      <td>64.65</td>\n",
       "      <td>64.30</td>\n",
       "      <td>93.26</td>\n",
       "      <td>92.72</td>\n",
       "      <td>93.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61.96</td>\n",
       "      <td>0.40</td>\n",
       "      <td>81.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>62.44</td>\n",
       "      <td>61.98</td>\n",
       "      <td>61.45</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.17</td>\n",
       "      <td>81.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>93.19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>65.70</td>\n",
       "      <td>64.55</td>\n",
       "      <td>64.75</td>\n",
       "      <td>93.36</td>\n",
       "      <td>92.84</td>\n",
       "      <td>93.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>92.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>65.22</td>\n",
       "      <td>64.23</td>\n",
       "      <td>64.09</td>\n",
       "      <td>92.55</td>\n",
       "      <td>92.06</td>\n",
       "      <td>92.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65.37</td>\n",
       "      <td>0.57</td>\n",
       "      <td>93.49</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>66.14</td>\n",
       "      <td>64.79</td>\n",
       "      <td>65.18</td>\n",
       "      <td>93.74</td>\n",
       "      <td>92.99</td>\n",
       "      <td>93.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61.95</td>\n",
       "      <td>0.58</td>\n",
       "      <td>81.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>62.75</td>\n",
       "      <td>61.67</td>\n",
       "      <td>61.42</td>\n",
       "      <td>82.12</td>\n",
       "      <td>81.34</td>\n",
       "      <td>81.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.23</td>\n",
       "      <td>0.59</td>\n",
       "      <td>93.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>66.03</td>\n",
       "      <td>64.63</td>\n",
       "      <td>65.03</td>\n",
       "      <td>93.53</td>\n",
       "      <td>92.92</td>\n",
       "      <td>93.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64.45</td>\n",
       "      <td>0.73</td>\n",
       "      <td>92.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>65.48</td>\n",
       "      <td>63.95</td>\n",
       "      <td>63.92</td>\n",
       "      <td>92.22</td>\n",
       "      <td>91.66</td>\n",
       "      <td>92.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>66.22</td>\n",
       "      <td>64.99</td>\n",
       "      <td>64.43</td>\n",
       "      <td>93.39</td>\n",
       "      <td>93.02</td>\n",
       "      <td>93.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>93.51</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>66.31</td>\n",
       "      <td>65.15</td>\n",
       "      <td>64.44</td>\n",
       "      <td>93.73</td>\n",
       "      <td>92.99</td>\n",
       "      <td>93.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>93.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>65.94</td>\n",
       "      <td>64.02</td>\n",
       "      <td>64.46</td>\n",
       "      <td>93.44</td>\n",
       "      <td>92.88</td>\n",
       "      <td>93.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65.06</td>\n",
       "      <td>0.86</td>\n",
       "      <td>92.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>66.27</td>\n",
       "      <td>64.33</td>\n",
       "      <td>64.58</td>\n",
       "      <td>93.06</td>\n",
       "      <td>92.71</td>\n",
       "      <td>93.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.62</td>\n",
       "      <td>0.89</td>\n",
       "      <td>93.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.06</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>65.60</td>\n",
       "      <td>64.81</td>\n",
       "      <td>63.45</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.02</td>\n",
       "      <td>93.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>92.51</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>65.69</td>\n",
       "      <td>64.74</td>\n",
       "      <td>63.27</td>\n",
       "      <td>92.55</td>\n",
       "      <td>92.07</td>\n",
       "      <td>92.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>61.67</td>\n",
       "      <td>1.05</td>\n",
       "      <td>81.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>63.12</td>\n",
       "      <td>60.71</td>\n",
       "      <td>61.16</td>\n",
       "      <td>81.27</td>\n",
       "      <td>80.78</td>\n",
       "      <td>82.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "0             64.75            0.40             93.26             0.44   \n",
       "12            61.96            0.40             81.39             0.34   \n",
       "6             65.00            0.50             93.19             0.25   \n",
       "10            64.51            0.51             92.50             0.35   \n",
       "8             65.37            0.57             93.49             0.35   \n",
       "13            61.95            0.58             81.65             0.34   \n",
       "4             65.23            0.59             93.40             0.36   \n",
       "9             64.45            0.73             92.15             0.38   \n",
       "3             65.21            0.75             93.29             0.19   \n",
       "7             65.30            0.77             93.51             0.38   \n",
       "2             64.81            0.82             93.28             0.29   \n",
       "5             65.06            0.86             92.99             0.21   \n",
       "1             64.62            0.89             93.24             0.26   \n",
       "11            64.57            1.00             92.51             0.34   \n",
       "14            61.67            1.05             81.38             0.55   \n",
       "\n",
       "    mean_fit_time param_vect__max_features param_vect__ngram_range  \\\n",
       "0            0.12                     None                  (1, 1)   \n",
       "12           0.07                     1000                  (1, 1)   \n",
       "6            0.07                    10000                  (1, 1)   \n",
       "10           0.07                     5000                  (1, 2)   \n",
       "8            0.07                    10000                  (1, 3)   \n",
       "13           0.06                     1000                  (1, 2)   \n",
       "4            0.08                    20000                  (1, 2)   \n",
       "9            0.06                     5000                  (1, 1)   \n",
       "3            0.07                    20000                  (1, 1)   \n",
       "7            0.07                    10000                  (1, 2)   \n",
       "2            0.07                     None                  (1, 3)   \n",
       "5            0.08                    20000                  (1, 3)   \n",
       "1            0.06                     None                  (1, 2)   \n",
       "11           0.08                     5000                  (1, 3)   \n",
       "14           0.06                     1000                  (1, 3)   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0               65.28              64.65              64.30   \n",
       "12              62.44              61.98              61.45   \n",
       "6               65.70              64.55              64.75   \n",
       "10              65.22              64.23              64.09   \n",
       "8               66.14              64.79              65.18   \n",
       "13              62.75              61.67              61.42   \n",
       "4               66.03              64.63              65.03   \n",
       "9               65.48              63.95              63.92   \n",
       "3               66.22              64.99              64.43   \n",
       "7               66.31              65.15              64.44   \n",
       "2               65.94              64.02              64.46   \n",
       "5               66.27              64.33              64.58   \n",
       "1               65.60              64.81              63.45   \n",
       "11              65.69              64.74              63.27   \n",
       "14              63.12              60.71              61.16   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \n",
       "0                93.26               92.72               93.79  \n",
       "12               81.88               81.17               81.13  \n",
       "6                93.36               92.84               93.36  \n",
       "10               92.55               92.06               92.90  \n",
       "8                93.74               92.99               93.73  \n",
       "13               82.12               81.34               81.50  \n",
       "4                93.53               92.92               93.77  \n",
       "9                92.22               91.66               92.58  \n",
       "3                93.39               93.02               93.46  \n",
       "7                93.73               92.99               93.82  \n",
       "2                93.44               92.88               93.53  \n",
       "5                93.06               92.71               93.21  \n",
       "1                93.60               93.02               93.11  \n",
       "11               92.55               92.07               92.92  \n",
       "14               81.27               80.78               82.10  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame()\n",
    "cv_results['mean_test_score'] = (grid.cv_results_['mean_test_score'] * 100).round(2)\n",
    "cv_results['std_test_score'] = (grid.cv_results_['std_test_score'] * 100).round(2)\n",
    "cv_results['mean_train_score'] = (grid.cv_results_['mean_train_score'] * 100).round(2)\n",
    "cv_results['std_train_score'] = (grid.cv_results_['std_train_score'] * 100).round(2)\n",
    "cv_results['mean_fit_time'] = grid.cv_results_['mean_fit_time'].round(2)\n",
    "cv_results = cv_results.join(pd.DataFrame(grid.cv_results_).filter(like='param_'))\n",
    "cv_results['split0_test_score'] = (grid.cv_results_['split0_test_score'] * 100).round(2)\n",
    "cv_results['split1_test_score'] = (grid.cv_results_['split1_test_score'] * 100).round(2)\n",
    "cv_results['split2_test_score'] = (grid.cv_results_['split2_test_score'] * 100).round(2)\n",
    "cv_results['split0_train_score'] = (grid.cv_results_['split0_train_score'] * 100).round(2)\n",
    "cv_results['split1_train_score'] = (grid.cv_results_['split1_train_score'] * 100).round(2)\n",
    "cv_results['split2_train_score'] = (grid.cv_results_['split2_train_score'] * 100).round(2)\n",
    "cv_results.sort_values('std_test_score', ascending=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
