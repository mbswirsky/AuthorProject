{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "Analyzes texts from seemingly-similar authors, Rachel Swirsky, Cat Valente, and Carmen Maria Machado, on a sentence-by-sentence basis, to see if their writing styles can be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data\n",
    "\n",
    "### Requesting and parsing html\n",
    "* Using requests and BeautifulSoup\n",
    "* The program first pulls stories directly from their published websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get raw in 12.89 seconds\n"
     ]
    }
   ],
   "source": [
    "# Pull stories from their websites\n",
    "\n",
    "header={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'}\n",
    "\n",
    "def get_raw(url, no_strong=False, no_b=False):\n",
    "    response = requests.get(url, headers=header)\n",
    "#     req = Request(url, headers=header)\n",
    "    html = response.content\n",
    "#     html = urlopen(req).read().decode('utf8')\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    if no_strong == True:\n",
    "        for strong in soup('strong'):\n",
    "            strong.decompose()\n",
    "    if no_b == True:\n",
    "        for b in soup('b'):\n",
    "            b.decompose()\n",
    "    return soup.get_text()\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# Swirsky stories\n",
    "dino_raw = get_raw('https://www.apex-magazine.com/if-you-were-a-dinosaur-my-love/')\n",
    "\n",
    "eros_raw = get_raw('https://www.tor.com/2009/03/03/eros-philia-agape/')\n",
    "\n",
    "still_raw = get_raw('http://uncannymagazine.com/article/love-is-never-still/', no_b=True)\n",
    "\n",
    "# Valente stories\n",
    "fade_raw = get_raw('http://clarkesworldmagazine.com/valente_08_12/')\n",
    "\n",
    "silent1_raw = get_raw('http://clarkesworldmagazine.com/valente_10_11/', no_strong=True)\n",
    "\n",
    "silent2_raw = get_raw('http://clarkesworldmagazine.com/valente_11_11/', no_strong=True)\n",
    "\n",
    "silent3_raw = get_raw('http://clarkesworldmagazine.com/valente_12_11/', no_strong=True)\n",
    "\n",
    "lion_raw = get_raw('http://uncannymagazine.com/article/planet-lion/')\n",
    "\n",
    "# Machado stories\n",
    "stitch_raw = get_raw('https://granta.com/The-Husband-Stitch/')\n",
    "\n",
    "follow_raw = get_raw('http://www.lightspeedmagazine.com/fiction/help-follow-sister-land-dead/')\n",
    "\n",
    "descent_raw = get_raw('http://www.nightmare-magazine.com/fiction/descent/')\n",
    "\n",
    "bites_raw = get_raw('http://texas.gulfcoastmag.org/journal/29.2-summer/fall-2017/eight-bites/')\n",
    "\n",
    "print('Get raw in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding story text in html\n",
    "* Using find() from BeautifulSoup\n",
    "* Identifies story text inside the total site text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select out story text\n",
    "\n",
    "def select_out(raw, start_text, end_text):\n",
    "    start = raw.find(start_text)\n",
    "    end = raw.find(end_text)\n",
    "    return raw[start:end+len(end_text)]\n",
    "\n",
    "dinosaur = select_out(dino_raw, \n",
    "                      'If you were a dinosaur, my', \n",
    "                      ', and the stuttering of my broken heart.'\n",
    "                     )\n",
    "eros = select_out(eros_raw, \n",
    "                  'Lucian packed his possessions before he left.', \n",
    "                  'yet form the thoughts to wonder what will happen next.\\nHe moves on.'\n",
    "                 )\n",
    "still = select_out(still_raw, \n",
    "                  'Through every moment of carving, I want her as one wants a woman. I want', \n",
    "                  'and decay, but it is also the early bloom that opens into winter’s cold. She is love, and she will always be reborn.'\n",
    "                  )\n",
    "fade = select_out(fade_raw, \n",
    "                 'ZOOM IN on a bright-eyed Betty in a crisp green dress,', \n",
    "                 'And over the black, a cheerful fat man giving the thumbs up to Sylvie, grinning:\\n\\nBuy Freedom Brand Film! It\\'s A-OK!'\n",
    "                 )\n",
    "silent1 = select_out(silent1_raw, \n",
    "                    'Inanna was called Queen of Heaven and Earth,', \n",
    "                    'The sun breaks the mountain crests, hard and cold, a shaft of white spilling over the black lake.'\n",
    "                    )\n",
    "silent2 = select_out(silent2_raw, \n",
    "                    'Humanity lived many years and ruled the earth,', \n",
    "                    'The castle windows go dark, one by one.'\n",
    "                    )\n",
    "silent3 = select_out(silent3_raw, \n",
    "                    'Tell me a story about yourself, Elefsis.', \n",
    "                    'we walk up the long path out of the churning, honey-colored sea.'\n",
    "                    )\n",
    "silent = silent1 + '\\n' + silent2 + '\\n' + silent3\n",
    "\n",
    "lion = select_out(lion_raw, \n",
    "                 'Initial Survey Report: Planet 6MQ441 (Bakeneko), Alaraph', \n",
    "                 'Szent Istvan. She longs to hear the first roar of her young.'\n",
    "                 )\n",
    "stitch = select_out(stitch_raw, \n",
    "                   '(If you read this story out loud, please use', \n",
    "                   'backwards off my neck and rolls off the bed, I feel as lonely as I have ever been.'\n",
    "                   )\n",
    "follow = select_out(follow_raw, \n",
    "                   'Help Me Follow My Sister\\ninto the Land of the Dead\\nby Ursula Ruiz', \n",
    "                   's—in a terrifying place where no mortal has any business treading.'\n",
    "                   ) + '\\n' + select_out(follow_raw, \n",
    "                                        'Home\\nThis is the thing about my sister and I:', \n",
    "                                        'Lucille L\\nJun 28, 2015\\nUrsula?'\n",
    "                                        )\n",
    "descent = select_out(descent_raw, \n",
    "                    'We gathered for the last time in October,', \n",
    "                    ', drinks cocked in their hands.\\nI looked down.'\n",
    "                    )\n",
    "bites = select_out(bites_raw, \n",
    "                  'As they put me to sleep, my mouth fills with the dust of the moon. I expect to choke on the silt but', \n",
    "                  'my charge.\\\"I\\'m sorry,\\\" I will whisper into her as she walks me toward the front door.\\\"I\\'m sorry,\\\" I will repeat. \\\"I didn\\'t know.\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Text\n",
    "\n",
    "### Cleaning \n",
    "* Cleaning out un-parseable symbols\n",
    "* Using re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(r'[\\[\\]]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean out bad symbols\n",
    "dinosaur = text_cleaner(dinosaur)\n",
    "eros = text_cleaner(eros)\n",
    "fade = text_cleaner(fade)\n",
    "silent = text_cleaner(silent)\n",
    "lion = text_cleaner(lion)\n",
    "still = text_cleaner(still)\n",
    "stitch = text_cleaner(stitch)\n",
    "follow = text_cleaner(follow)\n",
    "descent = text_cleaner(descent)\n",
    "bites = text_cleaner(bites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing documents\n",
    "* Using spaCy\n",
    "* Identifies sentence structure in the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed in 28.11 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parse using spaCy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "dinosaur_doc = nlp(dinosaur)\n",
    "eros_doc = nlp(eros)\n",
    "fade_doc = nlp(fade)\n",
    "silent_doc = nlp(silent)\n",
    "lion_doc = nlp(lion)\n",
    "still_doc = nlp(still)\n",
    "stitch_doc = nlp(stitch)\n",
    "follow_doc = nlp(follow)\n",
    "descent_doc = nlp(descent)\n",
    "bites_doc = nlp(bites)\n",
    "\n",
    "print('Parsed in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data into sentences\n",
    "* We use spaCy's tokenization and sentence identification\n",
    "* Creates one table of all the data, organized with one sentence for each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group sentences with their authors. (Each sentence will be a row.)\n",
    "\n",
    "dinosaur_sents = [[\"Swirsky\", sent.string] for sent in dinosaur_doc.sents]\n",
    "eros_sents = [[\"Swirsky\", sent.string] for sent in eros_doc.sents]\n",
    "still_sents = [[\"Swirsky\", sent.string] for sent in still_doc.sents]\n",
    "fade_sents = [[\"Valente\", sent.string] for sent in fade_doc.sents]\n",
    "silent_sents = [[\"Valente\", sent.string] for sent in silent_doc.sents]\n",
    "lion_sents = [[\"Valente\", sent.string] for sent in lion_doc.sents]\n",
    "stitch_sents = [[\"Machado\", sent.string] for sent in stitch_doc.sents]\n",
    "follow_sents = [[\"Machado\", sent.string] for sent in follow_doc.sents]\n",
    "descent_sents = [[\"Machado\", sent.string] for sent in descent_doc.sents]\n",
    "bites_sents = [[\"Machado\", sent.string] for sent in bites_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take part of speech of each word in each sentence.\n",
    "\n",
    "dinosaur_pos = [[token.pos_ for token in sent] for sent in dinosaur_doc.sents]\n",
    "eros_pos = [[token.pos_ for token in sent] for sent in eros_doc.sents]\n",
    "still_pos = [[token.pos_ for token in sent] for sent in still_doc.sents]\n",
    "fade_pos = [[token.pos_ for token in sent] for sent in fade_doc.sents]\n",
    "silent_pos = [[token.pos_ for token in sent] for sent in silent_doc.sents]\n",
    "lion_pos = [[token.pos_ for token in sent] for sent in lion_doc.sents]\n",
    "stitch_pos = [[token.pos_ for token in sent] for sent in stitch_doc.sents]\n",
    "follow_pos = [[token.pos_ for token in sent] for sent in follow_doc.sents]\n",
    "descent_pos = [[token.pos_ for token in sent] for sent in descent_doc.sents]\n",
    "bites_pos = [[token.pos_ for token in sent] for sent in bites_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(dinosaur_doc.print_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>2269</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>1880</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>1603</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  ratio\n",
       "Valente   2269   0.39\n",
       "Swirsky   1880   0.33\n",
       "Machado   1603   0.28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5752 total sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swirsky</td>\n",
       "      <td>if you were a dinosaur  my love  then you woul...</td>\n",
       "      <td>14</td>\n",
       "      <td>[ADP, PRON, VERB, DET, NOUN, PUNCT, ADJ, NOUN,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author                                               text  words  \\\n",
       "0  Swirsky  if you were a dinosaur  my love  then you woul...     14   \n",
       "\n",
       "                                                 pos  \n",
       "0  [ADP, PRON, VERB, DET, NOUN, PUNCT, ADJ, NOUN,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>Valente</td>\n",
       "      <td>was called queen of heaven and earth  queen o...</td>\n",
       "      <td>37</td>\n",
       "      <td>[PROPN, VERB, VERB, PROPN, ADP, PROPN, CCONJ, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                               text  words  \\\n",
       "2153  Valente   was called queen of heaven and earth  queen o...     37   \n",
       "\n",
       "                                                    pos  \n",
       "2153  [PROPN, VERB, VERB, PROPN, ADP, PROPN, CCONJ, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>Machado</td>\n",
       "      <td>if you read this story out loud  please use t...</td>\n",
       "      <td>24</td>\n",
       "      <td>[PUNCT, ADP, PRON, VERB, DET, NOUN, ADV, ADV, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                               text  words  \\\n",
       "4486  Machado   if you read this story out loud  please use t...     24   \n",
       "\n",
       "                                                    pos  \n",
       "4486  [PUNCT, ADP, PRON, VERB, DET, NOUN, ADV, ADV, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the sentences from the stories into one data frame.\n",
    "sentences = pd.DataFrame(dinosaur_sents + eros_sents + still_sents + fade_sents + silent_sents + lion_sents + stitch_sents + follow_sents + descent_sents + bites_sents)\n",
    "sentences.columns = ['author', 'text']\n",
    "\n",
    "# Strip out unnecessary punctuation.\n",
    "sentences['text'] = sentences['text'].str.lower().str.replace(r'[^a-zA-Z0-9 ]+', ' ').fillna('')\n",
    "\n",
    "# Word count per sentence.\n",
    "sentences['words'] = sentences['text'].str.split().apply(len)\n",
    "\n",
    "# Parts of speech classification of each word in sentence.\n",
    "sentences['pos'] = pd.Series(dinosaur_pos + eros_pos + still_pos + fade_pos + silent_pos + lion_pos + stitch_pos + follow_pos + descent_pos + bites_pos)\n",
    "\n",
    "# Remove blank sentences.\n",
    "sentences = sentences.loc[sentences['words'] > 0]\n",
    "\n",
    "# Remove proper nouns personal to each document.\n",
    "propn_pat = r'\\b(agogna|koetoi|adriana|lucian|galatea|aphrodite|hephaestus|fuoco|inanna|enki|erishkigal|salma|janet|lawrence|olive|luna|ursula|ceno|neva|elefsis|ravan|cassian|diane|ares|ben|seki|ilet)\\b'\n",
    "sentences['text'] = sentences['text'].str.replace(propn_pat, '')\n",
    "\n",
    "# Sentence counts by author.\n",
    "df_count = sentences.author.value_counts().to_frame(name='count')\n",
    "df_count['ratio'] = (df_count['count'] / len(sentences.author)).round(2)\n",
    "print('Full Data Set:')\n",
    "display(df_count)\n",
    "print('{} total sentences'.format(len(sentences.author)))\n",
    "display(sentences.loc[sentences['author'] == 'Swirsky'].head(1))\n",
    "display(sentences.loc[sentences['author'] == 'Valente'].head(1))\n",
    "display(sentences.loc[sentences['author'] == 'Machado'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Test Set\n",
    "This protects the vectorizer and regressor from over-fitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences.drop(['author', 'words'], axis=1), sentences['author'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "         count\n",
      "Valente   1807\n",
      "Swirsky   1514\n",
      "Machado   1280\n",
      "\n",
      "Test Set:\n",
      "         count\n",
      "Valente    462\n",
      "Swirsky    366\n",
      "Machado    323\n"
     ]
    }
   ],
   "source": [
    "print('Training Set:')\n",
    "print(y_train.value_counts().to_frame(name='count'))\n",
    "print('\\nTest Set:')\n",
    "print(y_test.value_counts().to_frame(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Selector, Transformers and Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Selector\n",
    "* Makes it possible to run different transformers on different columns of data before concatenating them together with FeatureUnion and then running through the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# The key corresponding to the desired value in a mappable.\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer\n",
    "\n",
    "* Try most common words across all texts\n",
    "* Bigrams and trigrams are arrangements of two- and three-words, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=str.split, \n",
    "                            stop_words='english', \n",
    "                            lowercase=True, \n",
    "                            use_idf=True, \n",
    "                            norm='l2', \n",
    "                            smooth_idf=True, \n",
    "                            max_features=None, \n",
    "                            ngram_range=(1,3), \n",
    "                            max_df=0.6, \n",
    "                            min_df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "# Extract features from each document for DictVectorizer\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, sents):\n",
    "        return [{'length': len(sent), \n",
    "                 'ADJ': sent.count('ADJ'), \n",
    "                 'NOUN': sent.count('NOUN'), \n",
    "                 'VERB': sent.count('VERB'), \n",
    "                 'ADV': sent.count('ADV'), \n",
    "                 'ADP': sent.count('ADP'), \n",
    "                 'CCONJ': sent.count('CCONJ'), \n",
    "                 'INTJ': sent.count('INTJ'), \n",
    "                 'PART': sent.count('PART'), \n",
    "                 'SCONJ': sent.count('SCONJ'), \n",
    "                 'PRON': sent.count('PRON'), \n",
    "                 'PROPN': sent.count('PROPN'), \n",
    "                 'DET': sent.count('DET'), \n",
    "                 'NUM': sent.count('NUM'), \n",
    "                 'AUX': sent.count('AUX'), \n",
    "                 'SYM': sent.count('SYM'), \n",
    "                }\n",
    "                for sent in sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# list of dicts -> feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier\n",
    "* Combines support vector classifier with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(penalty='elasticnet', \n",
    "                    alpha=0.0001, \n",
    "                    class_weight=None, \n",
    "                    loss='log', \n",
    "                    tol=0.005, \n",
    "                    fit_intercept=True, \n",
    "                    power_t=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* Chains transformers and estimator as input to grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')), \n",
    "                ('vect', vectorizer), \n",
    "            ])), \n",
    "            ('pos', Pipeline([\n",
    "                ('selector', ItemSelector(key='pos')), \n",
    "                ('stats', TextStats()), \n",
    "                ('dict', DictVectorizer()), \n",
    "            ])), \n",
    "        ], \n",
    "        transformer_weights={\n",
    "            'text': 1.0, \n",
    "            'pos': 1.0, \n",
    "        }, \n",
    "    )), \n",
    "    ('model', sgd), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Hyperparameters\n",
    "* List parameters to search over for best cv fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_features = [None, 20000, 10000, 5000, 1000]\n",
    "vect_ngrams = [(1,1), (1,2), (1,3)]\n",
    "vect_max = [0.6, 0.7, 0.8]\n",
    "vect_min = [1, 2, 3]\n",
    "vect_norm = ['l2', 'l1', None]\n",
    "model_alpha = [0.001, 0.0001, 0.00001]\n",
    "model_loss = ['hinge', 'log', 'squared_hinge', 'perceptron']\n",
    "model_tol = [0.01, 0.005, 0.001]\n",
    "model_class_weight = ['balanced', None]\n",
    "model_power_t = [0.4, 0.5, 0.6]\n",
    "model_penalty = ['l2', 'elasticnet', 'l1', 'none']\n",
    "model_intercept = [True, False]\n",
    "\n",
    "parameters = {\n",
    "#         'union__text__vect__max_features': vect_features, \n",
    "        'union__text__vect__ngram_range': vect_ngrams, \n",
    "#         'union__text__vect__max_df': vect_max, \n",
    "#         'union__text__vect__min_df': vect_min, \n",
    "#         'union__text__vect__norm': vect_norm, \n",
    "        'model__alpha': model_alpha, \n",
    "#         'model__loss': model_loss, \n",
    "#         'model__tol': model_tol,\n",
    "#         'model__class_weight': model_class_weight, \n",
    "#         'model__power_t': model_power_t, \n",
    "#         'model__penalty': model_penalty, \n",
    "#         'model__fit_intercept': model_intercept\n",
    "    }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    parameters, \n",
    "                    scoring='f1_weighted', \n",
    "                    return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed in 11.88 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Performing grid search...')\n",
    "t0 = time()\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\nCompleted in {:.2f} seconds'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Training Set Score: 52.71%\n",
      "\n",
      "Best Cross-Val Score: 46.53%\n",
      "\n",
      "Best Parameters:\n",
      "\n",
      "model__alpha: 0.0001\n",
      "union__text__vect__ngram_range: (1, 3)\n",
      "\n",
      "Test set score: 39.4%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Author</th>\n",
       "      <th>Machado</th>\n",
       "      <th>Swirsky</th>\n",
       "      <th>Valente</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Author  Machado  Swirsky  Valente\n",
       "Actual Author                              \n",
       "Machado               109        4      210\n",
       "Swirsky                42       15      309\n",
       "Valente                24        4      434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7768 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my</th>\n",
       "      <th>says</th>\n",
       "      <th>i</th>\n",
       "      <th>SYM</th>\n",
       "      <th>s</th>\n",
       "      <th>ribbon</th>\n",
       "      <th>2015</th>\n",
       "      <th>woman</th>\n",
       "      <th>jun</th>\n",
       "      <th>said</th>\n",
       "      <th>going</th>\n",
       "      <th>husband</th>\n",
       "      <th>cal</th>\n",
       "      <th>doctor</th>\n",
       "      <th>sister</th>\n",
       "      <th>son</th>\n",
       "      <th>parents</th>\n",
       "      <th>27</th>\n",
       "      <th>class</th>\n",
       "      <th>there</th>\n",
       "      <th>dead</th>\n",
       "      <th>after</th>\n",
       "      <th>then</th>\n",
       "      <th>girl</th>\n",
       "      <th>school</th>\n",
       "      <th>our</th>\n",
       "      <th>next</th>\n",
       "      <th>who</th>\n",
       "      <th>see</th>\n",
       "      <th>don</th>\n",
       "      <th>at</th>\n",
       "      <th>surgery</th>\n",
       "      <th>door</th>\n",
       "      <th>please</th>\n",
       "      <th>l</th>\n",
       "      <th>lucille</th>\n",
       "      <th>up</th>\n",
       "      <th>what</th>\n",
       "      <th>has</th>\n",
       "      <th>off</th>\n",
       "      <th>asks</th>\n",
       "      <th>come</th>\n",
       "      <th>down</th>\n",
       "      <th>say</th>\n",
       "      <th>heard</th>\n",
       "      <th>story</th>\n",
       "      <th>students</th>\n",
       "      <th>through</th>\n",
       "      <th>were</th>\n",
       "      <th>tell</th>\n",
       "      <th>...</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>her</th>\n",
       "      <th>oh</th>\n",
       "      <th>sun</th>\n",
       "      <th>myself</th>\n",
       "      <th>together</th>\n",
       "      <th>be</th>\n",
       "      <th>every</th>\n",
       "      <th>big</th>\n",
       "      <th>us</th>\n",
       "      <th>smallgod</th>\n",
       "      <th>into</th>\n",
       "      <th>machine</th>\n",
       "      <th>blue</th>\n",
       "      <th>wants</th>\n",
       "      <th>only</th>\n",
       "      <th>it</th>\n",
       "      <th>robot</th>\n",
       "      <th>they</th>\n",
       "      <th>bird</th>\n",
       "      <th>inside</th>\n",
       "      <th>called</th>\n",
       "      <th>one</th>\n",
       "      <th>stand</th>\n",
       "      <th>human</th>\n",
       "      <th>them</th>\n",
       "      <th>long</th>\n",
       "      <th>sea</th>\n",
       "      <th>would</th>\n",
       "      <th>how</th>\n",
       "      <th>loved</th>\n",
       "      <th>must</th>\n",
       "      <th>made</th>\n",
       "      <th>knew</th>\n",
       "      <th>their</th>\n",
       "      <th>too</th>\n",
       "      <th>could</th>\n",
       "      <th>in</th>\n",
       "      <th>rose</th>\n",
       "      <th>lions</th>\n",
       "      <th>of</th>\n",
       "      <th>all</th>\n",
       "      <th>lion</th>\n",
       "      <th>d</th>\n",
       "      <th>cannot</th>\n",
       "      <th>as</th>\n",
       "      <th>love</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>26.854746</td>\n",
       "      <td>12.611584</td>\n",
       "      <td>12.075381</td>\n",
       "      <td>10.974233</td>\n",
       "      <td>10.893000</td>\n",
       "      <td>9.844441</td>\n",
       "      <td>9.787224</td>\n",
       "      <td>9.463611</td>\n",
       "      <td>9.351161</td>\n",
       "      <td>8.964352</td>\n",
       "      <td>8.769149</td>\n",
       "      <td>8.700062</td>\n",
       "      <td>8.358956</td>\n",
       "      <td>8.175080</td>\n",
       "      <td>8.103821</td>\n",
       "      <td>7.794346</td>\n",
       "      <td>7.090002</td>\n",
       "      <td>7.011540</td>\n",
       "      <td>6.977786</td>\n",
       "      <td>6.900435</td>\n",
       "      <td>6.857790</td>\n",
       "      <td>6.755001</td>\n",
       "      <td>6.691444</td>\n",
       "      <td>6.281251</td>\n",
       "      <td>6.012543</td>\n",
       "      <td>5.830984</td>\n",
       "      <td>5.707720</td>\n",
       "      <td>5.687712</td>\n",
       "      <td>5.665579</td>\n",
       "      <td>5.640259</td>\n",
       "      <td>5.428575</td>\n",
       "      <td>5.369841</td>\n",
       "      <td>5.361315</td>\n",
       "      <td>5.216794</td>\n",
       "      <td>5.190975</td>\n",
       "      <td>5.190975</td>\n",
       "      <td>5.172966</td>\n",
       "      <td>4.868295</td>\n",
       "      <td>4.858208</td>\n",
       "      <td>4.857290</td>\n",
       "      <td>4.832315</td>\n",
       "      <td>4.790747</td>\n",
       "      <td>4.786919</td>\n",
       "      <td>4.754279</td>\n",
       "      <td>4.749013</td>\n",
       "      <td>4.736373</td>\n",
       "      <td>4.632901</td>\n",
       "      <td>4.611870</td>\n",
       "      <td>4.552359</td>\n",
       "      <td>4.548477</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>-3.834599</td>\n",
       "      <td>-3.856670</td>\n",
       "      <td>-3.908843</td>\n",
       "      <td>-3.921923</td>\n",
       "      <td>-3.962273</td>\n",
       "      <td>-3.988454</td>\n",
       "      <td>-3.996241</td>\n",
       "      <td>-4.079823</td>\n",
       "      <td>-4.145338</td>\n",
       "      <td>-4.159371</td>\n",
       "      <td>-4.161701</td>\n",
       "      <td>-4.185603</td>\n",
       "      <td>-4.204068</td>\n",
       "      <td>-4.296639</td>\n",
       "      <td>-4.367111</td>\n",
       "      <td>-4.618643</td>\n",
       "      <td>-4.623233</td>\n",
       "      <td>-4.830836</td>\n",
       "      <td>-4.899501</td>\n",
       "      <td>-4.920280</td>\n",
       "      <td>-4.920475</td>\n",
       "      <td>-4.942890</td>\n",
       "      <td>-4.943922</td>\n",
       "      <td>-4.974129</td>\n",
       "      <td>-4.981209</td>\n",
       "      <td>-5.018877</td>\n",
       "      <td>-5.026033</td>\n",
       "      <td>-5.091166</td>\n",
       "      <td>-5.11396</td>\n",
       "      <td>-5.187810</td>\n",
       "      <td>-5.209888</td>\n",
       "      <td>-5.218091</td>\n",
       "      <td>-5.377773</td>\n",
       "      <td>-5.450919</td>\n",
       "      <td>-5.494618</td>\n",
       "      <td>-5.790650</td>\n",
       "      <td>-6.153043</td>\n",
       "      <td>-6.366075</td>\n",
       "      <td>-6.598802</td>\n",
       "      <td>-6.907539</td>\n",
       "      <td>-7.292110</td>\n",
       "      <td>-7.343399</td>\n",
       "      <td>-7.748307</td>\n",
       "      <td>-8.000475</td>\n",
       "      <td>-8.084940</td>\n",
       "      <td>-8.961630</td>\n",
       "      <td>-10.700267</td>\n",
       "      <td>-12.419423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>-9.370058</td>\n",
       "      <td>-11.437370</td>\n",
       "      <td>-20.002094</td>\n",
       "      <td>-7.229800</td>\n",
       "      <td>4.110606</td>\n",
       "      <td>-4.561452</td>\n",
       "      <td>-0.371958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036150</td>\n",
       "      <td>-4.071046</td>\n",
       "      <td>-4.601775</td>\n",
       "      <td>-1.986760</td>\n",
       "      <td>-3.911285</td>\n",
       "      <td>-3.732567</td>\n",
       "      <td>-4.301541</td>\n",
       "      <td>-4.656631</td>\n",
       "      <td>-3.047690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.249852</td>\n",
       "      <td>-4.931946</td>\n",
       "      <td>-4.688954</td>\n",
       "      <td>-2.167075</td>\n",
       "      <td>2.661344</td>\n",
       "      <td>-3.298904</td>\n",
       "      <td>-2.169281</td>\n",
       "      <td>-7.688622</td>\n",
       "      <td>-1.901059</td>\n",
       "      <td>-7.344647</td>\n",
       "      <td>-2.497929</td>\n",
       "      <td>-3.808823</td>\n",
       "      <td>-1.094618</td>\n",
       "      <td>-4.170733</td>\n",
       "      <td>-1.636661</td>\n",
       "      <td>-3.459663</td>\n",
       "      <td>-0.209587</td>\n",
       "      <td>-0.209587</td>\n",
       "      <td>-7.601485</td>\n",
       "      <td>-6.921227</td>\n",
       "      <td>-5.821505</td>\n",
       "      <td>-3.404349</td>\n",
       "      <td>-4.963291</td>\n",
       "      <td>-6.974728</td>\n",
       "      <td>-2.374252</td>\n",
       "      <td>-9.214370</td>\n",
       "      <td>-1.647740</td>\n",
       "      <td>-5.907689</td>\n",
       "      <td>-2.201306</td>\n",
       "      <td>-0.974611</td>\n",
       "      <td>2.384317</td>\n",
       "      <td>-3.779312</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>6.388787</td>\n",
       "      <td>0.826104</td>\n",
       "      <td>6.045775</td>\n",
       "      <td>-4.650814</td>\n",
       "      <td>2.114645</td>\n",
       "      <td>-4.687791</td>\n",
       "      <td>-1.236145</td>\n",
       "      <td>-3.686210</td>\n",
       "      <td>-0.521873</td>\n",
       "      <td>-4.103489</td>\n",
       "      <td>1.155272</td>\n",
       "      <td>-2.872510</td>\n",
       "      <td>-3.599310</td>\n",
       "      <td>0.051623</td>\n",
       "      <td>1.593586</td>\n",
       "      <td>-9.769340</td>\n",
       "      <td>6.604045</td>\n",
       "      <td>0.178253</td>\n",
       "      <td>9.970373</td>\n",
       "      <td>-6.722751</td>\n",
       "      <td>-7.778889</td>\n",
       "      <td>-3.821410</td>\n",
       "      <td>0.919447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885803</td>\n",
       "      <td>-2.120800</td>\n",
       "      <td>-0.389865</td>\n",
       "      <td>5.293514</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.919888</td>\n",
       "      <td>9.762190</td>\n",
       "      <td>-1.870954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531475</td>\n",
       "      <td>5.137611</td>\n",
       "      <td>-3.891471</td>\n",
       "      <td>-3.425073</td>\n",
       "      <td>26.886043</td>\n",
       "      <td>-6.144661</td>\n",
       "      <td>-5.893138</td>\n",
       "      <td>-0.596477</td>\n",
       "      <td>-10.740881</td>\n",
       "      <td>20.258468</td>\n",
       "      <td>4.555253</td>\n",
       "      <td>6.552564</td>\n",
       "      <td>18.637015</td>\n",
       "      <td>-0.179778</td>\n",
       "      <td>-2.504517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>-12.745462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.521292</td>\n",
       "      <td>-3.891260</td>\n",
       "      <td>-12.868358</td>\n",
       "      <td>-4.930089</td>\n",
       "      <td>-8.146123</td>\n",
       "      <td>-8.776126</td>\n",
       "      <td>-8.095062</td>\n",
       "      <td>-3.813239</td>\n",
       "      <td>-6.137503</td>\n",
       "      <td>-6.724044</td>\n",
       "      <td>-4.148508</td>\n",
       "      <td>-3.809961</td>\n",
       "      <td>-3.345720</td>\n",
       "      <td>-2.934962</td>\n",
       "      <td>-3.043708</td>\n",
       "      <td>-5.701526</td>\n",
       "      <td>-3.625614</td>\n",
       "      <td>-2.675950</td>\n",
       "      <td>-1.956838</td>\n",
       "      <td>-4.720311</td>\n",
       "      <td>-8.164195</td>\n",
       "      <td>-2.339149</td>\n",
       "      <td>-3.261597</td>\n",
       "      <td>2.362142</td>\n",
       "      <td>-2.847932</td>\n",
       "      <td>0.822165</td>\n",
       "      <td>-4.827824</td>\n",
       "      <td>-2.023387</td>\n",
       "      <td>-2.554068</td>\n",
       "      <td>-1.385483</td>\n",
       "      <td>-2.065959</td>\n",
       "      <td>-1.937731</td>\n",
       "      <td>-3.929031</td>\n",
       "      <td>-3.929031</td>\n",
       "      <td>2.948565</td>\n",
       "      <td>1.248352</td>\n",
       "      <td>1.946817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.418256</td>\n",
       "      <td>0.050821</td>\n",
       "      <td>-2.851149</td>\n",
       "      <td>1.997412</td>\n",
       "      <td>-2.717344</td>\n",
       "      <td>1.415150</td>\n",
       "      <td>-2.422875</td>\n",
       "      <td>-2.807851</td>\n",
       "      <td>-6.418175</td>\n",
       "      <td>-0.649945</td>\n",
       "      <td>...</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>-0.888719</td>\n",
       "      <td>1.786035</td>\n",
       "      <td>-1.602313</td>\n",
       "      <td>6.707473</td>\n",
       "      <td>1.100826</td>\n",
       "      <td>7.116420</td>\n",
       "      <td>5.775953</td>\n",
       "      <td>7.658614</td>\n",
       "      <td>5.706972</td>\n",
       "      <td>7.093699</td>\n",
       "      <td>2.652787</td>\n",
       "      <td>6.041215</td>\n",
       "      <td>7.880258</td>\n",
       "      <td>4.190441</td>\n",
       "      <td>2.388611</td>\n",
       "      <td>11.325783</td>\n",
       "      <td>-1.721342</td>\n",
       "      <td>4.278704</td>\n",
       "      <td>-4.166784</td>\n",
       "      <td>10.202931</td>\n",
       "      <td>11.978301</td>\n",
       "      <td>6.854533</td>\n",
       "      <td>3.007100</td>\n",
       "      <td>3.693990</td>\n",
       "      <td>4.141947</td>\n",
       "      <td>6.510298</td>\n",
       "      <td>4.761049</td>\n",
       "      <td>-1.103040</td>\n",
       "      <td>4.63074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.014472</td>\n",
       "      <td>7.096671</td>\n",
       "      <td>4.238172</td>\n",
       "      <td>5.947806</td>\n",
       "      <td>1.490898</td>\n",
       "      <td>8.385402</td>\n",
       "      <td>8.735275</td>\n",
       "      <td>-17.882828</td>\n",
       "      <td>11.860810</td>\n",
       "      <td>10.284368</td>\n",
       "      <td>6.154192</td>\n",
       "      <td>16.910226</td>\n",
       "      <td>-10.939146</td>\n",
       "      <td>4.050741</td>\n",
       "      <td>1.068438</td>\n",
       "      <td>-9.021805</td>\n",
       "      <td>3.522003</td>\n",
       "      <td>11.010289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                my       says          i        SYM          s    ribbon  \\\n",
       "Machado  26.854746  12.611584  12.075381  10.974233  10.893000  9.844441   \n",
       "Swirsky  -9.370058 -11.437370 -20.002094  -7.229800   4.110606 -4.561452   \n",
       "Valente -12.745462   0.000000   2.521292  -3.891260 -12.868358 -4.930089   \n",
       "\n",
       "             2015     woman       jun      said     going   husband       cal  \\\n",
       "Machado  9.787224  9.463611  9.351161  8.964352  8.769149  8.700062  8.358956   \n",
       "Swirsky -0.371958  0.000000 -0.036150 -4.071046 -4.601775 -1.986760 -3.911285   \n",
       "Valente -8.146123 -8.776126 -8.095062 -3.813239 -6.137503 -6.724044 -4.148508   \n",
       "\n",
       "           doctor    sister       son   parents        27     class     there  \\\n",
       "Machado  8.175080  8.103821  7.794346  7.090002  7.011540  6.977786  6.900435   \n",
       "Swirsky -3.732567 -4.301541 -4.656631 -3.047690  0.000000 -2.249852 -4.931946   \n",
       "Valente -3.809961 -3.345720 -2.934962 -3.043708 -5.701526 -3.625614 -2.675950   \n",
       "\n",
       "             dead     after      then      girl    school       our      next  \\\n",
       "Machado  6.857790  6.755001  6.691444  6.281251  6.012543  5.830984  5.707720   \n",
       "Swirsky -4.688954 -2.167075  2.661344 -3.298904 -2.169281 -7.688622 -1.901059   \n",
       "Valente -1.956838 -4.720311 -8.164195 -2.339149 -3.261597  2.362142 -2.847932   \n",
       "\n",
       "              who       see       don        at   surgery      door    please  \\\n",
       "Machado  5.687712  5.665579  5.640259  5.428575  5.369841  5.361315  5.216794   \n",
       "Swirsky -7.344647 -2.497929 -3.808823 -1.094618 -4.170733 -1.636661 -3.459663   \n",
       "Valente  0.822165 -4.827824 -2.023387 -2.554068 -1.385483 -2.065959 -1.937731   \n",
       "\n",
       "                l   lucille        up      what       has       off      asks  \\\n",
       "Machado  5.190975  5.190975  5.172966  4.868295  4.858208  4.857290  4.832315   \n",
       "Swirsky -0.209587 -0.209587 -7.601485 -6.921227 -5.821505 -3.404349 -4.963291   \n",
       "Valente -3.929031 -3.929031  2.948565  1.248352  1.946817  0.000000 -0.418256   \n",
       "\n",
       "             come      down       say     heard     story  students   through  \\\n",
       "Machado  4.790747  4.786919  4.754279  4.749013  4.736373  4.632901  4.611870   \n",
       "Swirsky -6.974728 -2.374252 -9.214370 -1.647740 -5.907689 -2.201306 -0.974611   \n",
       "Valente  0.050821 -2.851149  1.997412 -2.717344  1.415150 -2.422875 -2.807851   \n",
       "\n",
       "             were      tell    ...          hole  watering       her  \\\n",
       "Machado  4.552359  4.548477    ...     -3.806771 -3.806771 -3.834599   \n",
       "Swirsky  2.384317 -3.779312    ...     -5.149635 -5.149635  6.388787   \n",
       "Valente -6.418175 -0.649945    ...      8.954025  8.954025 -0.888719   \n",
       "\n",
       "               oh       sun    myself  together        be     every       big  \\\n",
       "Machado -3.856670 -3.908843 -3.921923 -3.962273 -3.988454 -3.996241 -4.079823   \n",
       "Swirsky  0.826104  6.045775 -4.650814  2.114645 -4.687791 -1.236145 -3.686210   \n",
       "Valente  1.786035 -1.602313  6.707473  1.100826  7.116420  5.775953  7.658614   \n",
       "\n",
       "               us  smallgod      into   machine      blue     wants      only  \\\n",
       "Machado -4.145338 -4.159371 -4.161701 -4.185603 -4.204068 -4.296639 -4.367111   \n",
       "Swirsky -0.521873 -4.103489  1.155272 -2.872510 -3.599310  0.051623  1.593586   \n",
       "Valente  5.706972  7.093699  2.652787  6.041215  7.880258  4.190441  2.388611   \n",
       "\n",
       "                it     robot      they      bird     inside     called  \\\n",
       "Machado  -4.618643 -4.623233 -4.830836 -4.899501  -4.920280  -4.920475   \n",
       "Swirsky  -9.769340  6.604045  0.178253  9.970373  -6.722751  -7.778889   \n",
       "Valente  11.325783 -1.721342  4.278704 -4.166784  10.202931  11.978301   \n",
       "\n",
       "              one     stand     human      them      long       sea     would  \\\n",
       "Machado -4.942890 -4.943922 -4.974129 -4.981209 -5.018877 -5.026033 -5.091166   \n",
       "Swirsky -3.821410  0.919447  0.000000  0.885803 -2.120800 -0.389865  5.293514   \n",
       "Valente  6.854533  3.007100  3.693990  4.141947  6.510298  4.761049 -1.103040   \n",
       "\n",
       "             how     loved      must      made      knew     their       too  \\\n",
       "Machado -5.11396 -5.187810 -5.209888 -5.218091 -5.377773 -5.450919 -5.494618   \n",
       "Swirsky  0.00000  3.919888  9.762190 -1.870954  0.000000 -0.531475  5.137611   \n",
       "Valente  4.63074  0.000000 -3.014472  7.096671  4.238172  5.947806  1.490898   \n",
       "\n",
       "            could        in       rose      lions         of       all  \\\n",
       "Machado -5.790650 -6.153043  -6.366075  -6.598802  -6.907539 -7.292110   \n",
       "Swirsky -3.891471 -3.425073  26.886043  -6.144661  -5.893138 -0.596477   \n",
       "Valente  8.385402  8.735275 -17.882828  11.860810  10.284368  6.154192   \n",
       "\n",
       "              lion          d    cannot        as       love      PROPN  \\\n",
       "Machado  -7.343399  -7.748307 -8.000475 -8.084940  -8.961630 -10.700267   \n",
       "Swirsky -10.740881  20.258468  4.555253  6.552564  18.637015  -0.179778   \n",
       "Valente  16.910226 -10.939146  4.050741  1.068438  -9.021805   3.522003   \n",
       "\n",
       "               not  \n",
       "Machado -12.419423  \n",
       "Swirsky  -2.504517  \n",
       "Valente  11.010289  \n",
       "\n",
       "[3 rows x 7768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rose</th>\n",
       "      <th>he</th>\n",
       "      <th>his</th>\n",
       "      <th>d</th>\n",
       "      <th>love</th>\n",
       "      <th>him</th>\n",
       "      <th>bird</th>\n",
       "      <th>must</th>\n",
       "      <th>she</th>\n",
       "      <th>okay</th>\n",
       "      <th>the</th>\n",
       "      <th>will</th>\n",
       "      <th>against</th>\n",
       "      <th>across</th>\n",
       "      <th>moment</th>\n",
       "      <th>take</th>\n",
       "      <th>until</th>\n",
       "      <th>ivory</th>\n",
       "      <th>robot</th>\n",
       "      <th>as</th>\n",
       "      <th>her</th>\n",
       "      <th>sun</th>\n",
       "      <th>toward</th>\n",
       "      <th>felt</th>\n",
       "      <th>pedestal</th>\n",
       "      <th>driver</th>\n",
       "      <th>would</th>\n",
       "      <th>from</th>\n",
       "      <th>course</th>\n",
       "      <th>too</th>\n",
       "      <th>movement</th>\n",
       "      <th>that</th>\n",
       "      <th>am</th>\n",
       "      <th>sculptor</th>\n",
       "      <th>another</th>\n",
       "      <th>teenager</th>\n",
       "      <th>hammer</th>\n",
       "      <th>cannot</th>\n",
       "      <th>statue</th>\n",
       "      <th>arm</th>\n",
       "      <th>ground</th>\n",
       "      <th>gods</th>\n",
       "      <th>mine</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>s</th>\n",
       "      <th>wine</th>\n",
       "      <th>laughter</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>same</th>\n",
       "      <th>lambs</th>\n",
       "      <th>...</th>\n",
       "      <th>son</th>\n",
       "      <th>over</th>\n",
       "      <th>be</th>\n",
       "      <th>dead</th>\n",
       "      <th>look</th>\n",
       "      <th>everyone</th>\n",
       "      <th>body</th>\n",
       "      <th>there</th>\n",
       "      <th>asks</th>\n",
       "      <th>looks</th>\n",
       "      <th>very</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>dreaming</th>\n",
       "      <th>because</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>me</th>\n",
       "      <th>came</th>\n",
       "      <th>has</th>\n",
       "      <th>of</th>\n",
       "      <th>child</th>\n",
       "      <th>story</th>\n",
       "      <th>have</th>\n",
       "      <th>lions</th>\n",
       "      <th>out</th>\n",
       "      <th>inside</th>\n",
       "      <th>name</th>\n",
       "      <th>what</th>\n",
       "      <th>come</th>\n",
       "      <th>SYM</th>\n",
       "      <th>who</th>\n",
       "      <th>just</th>\n",
       "      <th>is</th>\n",
       "      <th>up</th>\n",
       "      <th>our</th>\n",
       "      <th>had</th>\n",
       "      <th>called</th>\n",
       "      <th>you</th>\n",
       "      <th>did</th>\n",
       "      <th>NUM</th>\n",
       "      <th>mother</th>\n",
       "      <th>about</th>\n",
       "      <th>say</th>\n",
       "      <th>my</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>lion</th>\n",
       "      <th>says</th>\n",
       "      <th>we</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>-6.366075</td>\n",
       "      <td>-3.620684</td>\n",
       "      <td>-1.886455</td>\n",
       "      <td>-7.748307</td>\n",
       "      <td>-8.961630</td>\n",
       "      <td>-2.256784</td>\n",
       "      <td>-4.899501</td>\n",
       "      <td>-5.209888</td>\n",
       "      <td>-0.277577</td>\n",
       "      <td>-3.779533</td>\n",
       "      <td>-1.398438</td>\n",
       "      <td>-0.512355</td>\n",
       "      <td>1.303212</td>\n",
       "      <td>-1.250450</td>\n",
       "      <td>-3.238129</td>\n",
       "      <td>-3.531191</td>\n",
       "      <td>-1.271770</td>\n",
       "      <td>-2.851464</td>\n",
       "      <td>-4.623233</td>\n",
       "      <td>-8.084940</td>\n",
       "      <td>-3.834599</td>\n",
       "      <td>-3.908843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.553357</td>\n",
       "      <td>-2.037857</td>\n",
       "      <td>-2.439066</td>\n",
       "      <td>-5.091166</td>\n",
       "      <td>3.726362</td>\n",
       "      <td>-2.533769</td>\n",
       "      <td>-5.494618</td>\n",
       "      <td>-0.918084</td>\n",
       "      <td>-2.167644</td>\n",
       "      <td>-2.614881</td>\n",
       "      <td>-2.444338</td>\n",
       "      <td>1.518332</td>\n",
       "      <td>-1.319720</td>\n",
       "      <td>-2.358041</td>\n",
       "      <td>-8.000475</td>\n",
       "      <td>-1.765714</td>\n",
       "      <td>-1.208091</td>\n",
       "      <td>-2.201311</td>\n",
       "      <td>-2.047593</td>\n",
       "      <td>-1.872420</td>\n",
       "      <td>-2.999758</td>\n",
       "      <td>10.893000</td>\n",
       "      <td>-0.807314</td>\n",
       "      <td>-0.134672</td>\n",
       "      <td>-1.991628</td>\n",
       "      <td>-0.440818</td>\n",
       "      <td>-1.761524</td>\n",
       "      <td>...</td>\n",
       "      <td>7.794346</td>\n",
       "      <td>1.892889</td>\n",
       "      <td>-3.988454</td>\n",
       "      <td>6.857790</td>\n",
       "      <td>4.243992</td>\n",
       "      <td>1.569779</td>\n",
       "      <td>-0.162113</td>\n",
       "      <td>6.900435</td>\n",
       "      <td>4.832315</td>\n",
       "      <td>1.912317</td>\n",
       "      <td>1.232124</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.367931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.790132</td>\n",
       "      <td>1.226084</td>\n",
       "      <td>4.858208</td>\n",
       "      <td>-6.907539</td>\n",
       "      <td>-1.566462</td>\n",
       "      <td>4.736373</td>\n",
       "      <td>-1.898791</td>\n",
       "      <td>-6.598802</td>\n",
       "      <td>2.721899</td>\n",
       "      <td>-4.920280</td>\n",
       "      <td>1.294486</td>\n",
       "      <td>4.868295</td>\n",
       "      <td>4.790747</td>\n",
       "      <td>10.974233</td>\n",
       "      <td>5.687712</td>\n",
       "      <td>3.965798</td>\n",
       "      <td>2.757684</td>\n",
       "      <td>5.172966</td>\n",
       "      <td>5.830984</td>\n",
       "      <td>-0.320036</td>\n",
       "      <td>-4.920475</td>\n",
       "      <td>-1.602298</td>\n",
       "      <td>-2.787690</td>\n",
       "      <td>1.517743</td>\n",
       "      <td>2.430100</td>\n",
       "      <td>4.129324</td>\n",
       "      <td>4.754279</td>\n",
       "      <td>26.854746</td>\n",
       "      <td>-4.618643</td>\n",
       "      <td>-0.467731</td>\n",
       "      <td>-7.343399</td>\n",
       "      <td>12.611584</td>\n",
       "      <td>-0.985465</td>\n",
       "      <td>12.075381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>26.886043</td>\n",
       "      <td>23.184698</td>\n",
       "      <td>22.343143</td>\n",
       "      <td>20.258468</td>\n",
       "      <td>18.637015</td>\n",
       "      <td>16.067249</td>\n",
       "      <td>9.970373</td>\n",
       "      <td>9.762190</td>\n",
       "      <td>8.580404</td>\n",
       "      <td>8.414869</td>\n",
       "      <td>8.161367</td>\n",
       "      <td>8.008137</td>\n",
       "      <td>7.419023</td>\n",
       "      <td>7.382059</td>\n",
       "      <td>7.246676</td>\n",
       "      <td>7.154290</td>\n",
       "      <td>7.065640</td>\n",
       "      <td>6.620749</td>\n",
       "      <td>6.604045</td>\n",
       "      <td>6.552564</td>\n",
       "      <td>6.388787</td>\n",
       "      <td>6.045775</td>\n",
       "      <td>6.004314</td>\n",
       "      <td>5.988648</td>\n",
       "      <td>5.740544</td>\n",
       "      <td>5.727580</td>\n",
       "      <td>5.293514</td>\n",
       "      <td>5.265388</td>\n",
       "      <td>5.185785</td>\n",
       "      <td>5.137611</td>\n",
       "      <td>4.873344</td>\n",
       "      <td>4.841594</td>\n",
       "      <td>4.819696</td>\n",
       "      <td>4.727480</td>\n",
       "      <td>4.703701</td>\n",
       "      <td>4.685742</td>\n",
       "      <td>4.634237</td>\n",
       "      <td>4.555253</td>\n",
       "      <td>4.251969</td>\n",
       "      <td>4.251547</td>\n",
       "      <td>4.220706</td>\n",
       "      <td>4.208075</td>\n",
       "      <td>4.184126</td>\n",
       "      <td>4.146367</td>\n",
       "      <td>4.110606</td>\n",
       "      <td>4.108331</td>\n",
       "      <td>4.072632</td>\n",
       "      <td>4.071693</td>\n",
       "      <td>4.064144</td>\n",
       "      <td>4.027742</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.656631</td>\n",
       "      <td>-4.667038</td>\n",
       "      <td>-4.687791</td>\n",
       "      <td>-4.688954</td>\n",
       "      <td>-4.724501</td>\n",
       "      <td>-4.899215</td>\n",
       "      <td>-4.919787</td>\n",
       "      <td>-4.931946</td>\n",
       "      <td>-4.963291</td>\n",
       "      <td>-5.033427</td>\n",
       "      <td>-5.034918</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>-5.188043</td>\n",
       "      <td>-5.492877</td>\n",
       "      <td>-5.546572</td>\n",
       "      <td>-5.645614</td>\n",
       "      <td>-5.718790</td>\n",
       "      <td>-5.821505</td>\n",
       "      <td>-5.893138</td>\n",
       "      <td>-5.905844</td>\n",
       "      <td>-5.907689</td>\n",
       "      <td>-6.031405</td>\n",
       "      <td>-6.144661</td>\n",
       "      <td>-6.184882</td>\n",
       "      <td>-6.722751</td>\n",
       "      <td>-6.902575</td>\n",
       "      <td>-6.921227</td>\n",
       "      <td>-6.974728</td>\n",
       "      <td>-7.229800</td>\n",
       "      <td>-7.344647</td>\n",
       "      <td>-7.358239</td>\n",
       "      <td>-7.561574</td>\n",
       "      <td>-7.601485</td>\n",
       "      <td>-7.688622</td>\n",
       "      <td>-7.690669</td>\n",
       "      <td>-7.778889</td>\n",
       "      <td>-7.879098</td>\n",
       "      <td>-8.194708</td>\n",
       "      <td>-9.051403</td>\n",
       "      <td>-9.069397</td>\n",
       "      <td>-9.212396</td>\n",
       "      <td>-9.214370</td>\n",
       "      <td>-9.370058</td>\n",
       "      <td>-9.769340</td>\n",
       "      <td>-10.202977</td>\n",
       "      <td>-10.740881</td>\n",
       "      <td>-11.437370</td>\n",
       "      <td>-14.890550</td>\n",
       "      <td>-20.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>-17.882828</td>\n",
       "      <td>-16.732626</td>\n",
       "      <td>-14.832010</td>\n",
       "      <td>-10.939146</td>\n",
       "      <td>-9.021805</td>\n",
       "      <td>-10.805114</td>\n",
       "      <td>-4.166784</td>\n",
       "      <td>-3.014472</td>\n",
       "      <td>-4.428721</td>\n",
       "      <td>-3.902878</td>\n",
       "      <td>-4.916381</td>\n",
       "      <td>-6.754588</td>\n",
       "      <td>-7.785247</td>\n",
       "      <td>-4.990822</td>\n",
       "      <td>-3.144129</td>\n",
       "      <td>-2.883578</td>\n",
       "      <td>-3.851584</td>\n",
       "      <td>-3.068426</td>\n",
       "      <td>-1.721342</td>\n",
       "      <td>1.068438</td>\n",
       "      <td>-0.888719</td>\n",
       "      <td>-1.602313</td>\n",
       "      <td>-4.115927</td>\n",
       "      <td>-4.261547</td>\n",
       "      <td>-2.826169</td>\n",
       "      <td>-2.381562</td>\n",
       "      <td>-1.103040</td>\n",
       "      <td>-7.478183</td>\n",
       "      <td>-1.733523</td>\n",
       "      <td>1.490898</td>\n",
       "      <td>-3.149624</td>\n",
       "      <td>-2.934579</td>\n",
       "      <td>-0.707958</td>\n",
       "      <td>-1.833026</td>\n",
       "      <td>-5.062905</td>\n",
       "      <td>-1.885756</td>\n",
       "      <td>-2.660507</td>\n",
       "      <td>4.050741</td>\n",
       "      <td>-1.993454</td>\n",
       "      <td>-2.909092</td>\n",
       "      <td>-1.381503</td>\n",
       "      <td>-2.220854</td>\n",
       "      <td>-1.691531</td>\n",
       "      <td>-1.052923</td>\n",
       "      <td>-12.868358</td>\n",
       "      <td>-3.540781</td>\n",
       "      <td>-3.562886</td>\n",
       "      <td>0.188412</td>\n",
       "      <td>-2.578907</td>\n",
       "      <td>-2.294095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.934962</td>\n",
       "      <td>0.912679</td>\n",
       "      <td>7.116420</td>\n",
       "      <td>-1.956838</td>\n",
       "      <td>0.915708</td>\n",
       "      <td>2.218873</td>\n",
       "      <td>5.749492</td>\n",
       "      <td>-2.675950</td>\n",
       "      <td>-0.418256</td>\n",
       "      <td>2.599129</td>\n",
       "      <td>3.741919</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>4.991169</td>\n",
       "      <td>1.063380</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>5.448154</td>\n",
       "      <td>3.154562</td>\n",
       "      <td>1.946817</td>\n",
       "      <td>10.284368</td>\n",
       "      <td>6.298453</td>\n",
       "      <td>1.415150</td>\n",
       "      <td>4.917788</td>\n",
       "      <td>11.860810</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>10.202931</td>\n",
       "      <td>4.328888</td>\n",
       "      <td>1.248352</td>\n",
       "      <td>0.050821</td>\n",
       "      <td>-3.891260</td>\n",
       "      <td>0.822165</td>\n",
       "      <td>1.462735</td>\n",
       "      <td>2.412734</td>\n",
       "      <td>2.948565</td>\n",
       "      <td>2.362142</td>\n",
       "      <td>7.561372</td>\n",
       "      <td>11.978301</td>\n",
       "      <td>6.685772</td>\n",
       "      <td>9.166470</td>\n",
       "      <td>1.726266</td>\n",
       "      <td>6.349802</td>\n",
       "      <td>4.033395</td>\n",
       "      <td>1.997412</td>\n",
       "      <td>-12.745462</td>\n",
       "      <td>11.325783</td>\n",
       "      <td>7.811434</td>\n",
       "      <td>16.910226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.136132</td>\n",
       "      <td>2.521292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              rose         he        his          d       love        him  \\\n",
       "Machado  -6.366075  -3.620684  -1.886455  -7.748307  -8.961630  -2.256784   \n",
       "Swirsky  26.886043  23.184698  22.343143  20.258468  18.637015  16.067249   \n",
       "Valente -17.882828 -16.732626 -14.832010 -10.939146  -9.021805 -10.805114   \n",
       "\n",
       "             bird      must       she      okay       the      will   against  \\\n",
       "Machado -4.899501 -5.209888 -0.277577 -3.779533 -1.398438 -0.512355  1.303212   \n",
       "Swirsky  9.970373  9.762190  8.580404  8.414869  8.161367  8.008137  7.419023   \n",
       "Valente -4.166784 -3.014472 -4.428721 -3.902878 -4.916381 -6.754588 -7.785247   \n",
       "\n",
       "           across    moment      take     until     ivory     robot        as  \\\n",
       "Machado -1.250450 -3.238129 -3.531191 -1.271770 -2.851464 -4.623233 -8.084940   \n",
       "Swirsky  7.382059  7.246676  7.154290  7.065640  6.620749  6.604045  6.552564   \n",
       "Valente -4.990822 -3.144129 -2.883578 -3.851584 -3.068426 -1.721342  1.068438   \n",
       "\n",
       "              her       sun    toward      felt  pedestal    driver     would  \\\n",
       "Machado -3.834599 -3.908843  0.000000 -1.553357 -2.037857 -2.439066 -5.091166   \n",
       "Swirsky  6.388787  6.045775  6.004314  5.988648  5.740544  5.727580  5.293514   \n",
       "Valente -0.888719 -1.602313 -4.115927 -4.261547 -2.826169 -2.381562 -1.103040   \n",
       "\n",
       "             from    course       too  movement      that        am  sculptor  \\\n",
       "Machado  3.726362 -2.533769 -5.494618 -0.918084 -2.167644 -2.614881 -2.444338   \n",
       "Swirsky  5.265388  5.185785  5.137611  4.873344  4.841594  4.819696  4.727480   \n",
       "Valente -7.478183 -1.733523  1.490898 -3.149624 -2.934579 -0.707958 -1.833026   \n",
       "\n",
       "          another  teenager    hammer    cannot    statue       arm    ground  \\\n",
       "Machado  1.518332 -1.319720 -2.358041 -8.000475 -1.765714 -1.208091 -2.201311   \n",
       "Swirsky  4.703701  4.685742  4.634237  4.555253  4.251969  4.251547  4.220706   \n",
       "Valente -5.062905 -1.885756 -2.660507  4.050741 -1.993454 -2.909092 -1.381503   \n",
       "\n",
       "             gods      mine  beautiful          s      wine  laughter  \\\n",
       "Machado -2.047593 -1.872420  -2.999758  10.893000 -0.807314 -0.134672   \n",
       "Swirsky  4.208075  4.184126   4.146367   4.110606  4.108331  4.072632   \n",
       "Valente -2.220854 -1.691531  -1.052923 -12.868358 -3.540781 -3.562886   \n",
       "\n",
       "             NOUN      same     lambs    ...           son      over  \\\n",
       "Machado -1.991628 -0.440818 -1.761524    ...      7.794346  1.892889   \n",
       "Swirsky  4.071693  4.064144  4.027742    ...     -4.656631 -4.667038   \n",
       "Valente  0.188412 -2.578907 -2.294095    ...     -2.934962  0.912679   \n",
       "\n",
       "               be      dead      look  everyone      body     there      asks  \\\n",
       "Machado -3.988454  6.857790  4.243992  1.569779 -0.162113  6.900435  4.832315   \n",
       "Swirsky -4.687791 -4.688954 -4.724501 -4.899215 -4.919787 -4.931946 -4.963291   \n",
       "Valente  7.116420 -1.956838  0.915708  2.218873  5.749492 -2.675950 -0.418256   \n",
       "\n",
       "            looks      very      hole  watering  dreaming   because     CCONJ  \\\n",
       "Machado  1.912317  1.232124 -3.806771 -3.806771  0.000000  4.367931  0.000000   \n",
       "Swirsky -5.033427 -5.034918 -5.149635 -5.149635 -5.188043 -5.492877 -5.546572   \n",
       "Valente  2.599129  3.741919  8.954025  8.954025  4.991169  1.063380  1.701675   \n",
       "\n",
       "               me      came       has         of     child     story  \\\n",
       "Machado -0.790132  1.226084  4.858208  -6.907539 -1.566462  4.736373   \n",
       "Swirsky -5.645614 -5.718790 -5.821505  -5.893138 -5.905844 -5.907689   \n",
       "Valente  5.448154  3.154562  1.946817  10.284368  6.298453  1.415150   \n",
       "\n",
       "             have      lions       out     inside      name      what  \\\n",
       "Machado -1.898791  -6.598802  2.721899  -4.920280  1.294486  4.868295   \n",
       "Swirsky -6.031405  -6.144661 -6.184882  -6.722751 -6.902575 -6.921227   \n",
       "Valente  4.917788  11.860810  2.257143  10.202931  4.328888  1.248352   \n",
       "\n",
       "             come        SYM       who      just        is        up  \\\n",
       "Machado  4.790747  10.974233  5.687712  3.965798  2.757684  5.172966   \n",
       "Swirsky -6.974728  -7.229800 -7.344647 -7.358239 -7.561574 -7.601485   \n",
       "Valente  0.050821  -3.891260  0.822165  1.462735  2.412734  2.948565   \n",
       "\n",
       "              our       had     called       you       did       NUM  \\\n",
       "Machado  5.830984 -0.320036  -4.920475 -1.602298 -2.787690  1.517743   \n",
       "Swirsky -7.688622 -7.690669  -7.778889 -7.879098 -8.194708 -9.051403   \n",
       "Valente  2.362142  7.561372  11.978301  6.685772  9.166470  1.726266   \n",
       "\n",
       "           mother     about       say         my         it       like  \\\n",
       "Machado  2.430100  4.129324  4.754279  26.854746  -4.618643  -0.467731   \n",
       "Swirsky -9.069397 -9.212396 -9.214370  -9.370058  -9.769340 -10.202977   \n",
       "Valente  6.349802  4.033395  1.997412 -12.745462  11.325783   7.811434   \n",
       "\n",
       "              lion       says         we          i  \n",
       "Machado  -7.343399  12.611584  -0.985465  12.075381  \n",
       "Swirsky -10.740881 -11.437370 -14.890550 -20.002094  \n",
       "Valente  16.910226   0.000000  12.136132   2.521292  \n",
       "\n",
       "[3 rows x 7768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lion</th>\n",
       "      <th>we</th>\n",
       "      <th>called</th>\n",
       "      <th>lions</th>\n",
       "      <th>it</th>\n",
       "      <th>not</th>\n",
       "      <th>of</th>\n",
       "      <th>inside</th>\n",
       "      <th>did</th>\n",
       "      <th>hole</th>\n",
       "      <th>watering</th>\n",
       "      <th>in</th>\n",
       "      <th>could</th>\n",
       "      <th>blue</th>\n",
       "      <th>like</th>\n",
       "      <th>big</th>\n",
       "      <th>had</th>\n",
       "      <th>well</th>\n",
       "      <th>be</th>\n",
       "      <th>made</th>\n",
       "      <th>smallgod</th>\n",
       "      <th>one</th>\n",
       "      <th>dormouse</th>\n",
       "      <th>myself</th>\n",
       "      <th>you</th>\n",
       "      <th>long</th>\n",
       "      <th>uplink</th>\n",
       "      <th>mother</th>\n",
       "      <th>jewel</th>\n",
       "      <th>child</th>\n",
       "      <th>all</th>\n",
       "      <th>black</th>\n",
       "      <th>machine</th>\n",
       "      <th>their</th>\n",
       "      <th>every</th>\n",
       "      <th>body</th>\n",
       "      <th>yttrium</th>\n",
       "      <th>us</th>\n",
       "      <th>done</th>\n",
       "      <th>me</th>\n",
       "      <th>perhaps</th>\n",
       "      <th>dreambody</th>\n",
       "      <th>means</th>\n",
       "      <th>anything</th>\n",
       "      <th>dreaming</th>\n",
       "      <th>have</th>\n",
       "      <th>green</th>\n",
       "      <th>house</th>\n",
       "      <th>steelveldt</th>\n",
       "      <th>really</th>\n",
       "      <th>...</th>\n",
       "      <th>laughter</th>\n",
       "      <th>feet</th>\n",
       "      <th>class</th>\n",
       "      <th>and</th>\n",
       "      <th>doctor</th>\n",
       "      <th>said</th>\n",
       "      <th>until</th>\n",
       "      <th>hand</th>\n",
       "      <th>father</th>\n",
       "      <th>SYM</th>\n",
       "      <th>okay</th>\n",
       "      <th>fingers</th>\n",
       "      <th>l</th>\n",
       "      <th>lucille</th>\n",
       "      <th>toward</th>\n",
       "      <th>cal</th>\n",
       "      <th>bird</th>\n",
       "      <th>last</th>\n",
       "      <th>felt</th>\n",
       "      <th>cold</th>\n",
       "      <th>she</th>\n",
       "      <th>after</th>\n",
       "      <th>something</th>\n",
       "      <th>see</th>\n",
       "      <th>the</th>\n",
       "      <th>ribbon</th>\n",
       "      <th>across</th>\n",
       "      <th>another</th>\n",
       "      <th>new</th>\n",
       "      <th>away</th>\n",
       "      <th>27</th>\n",
       "      <th>going</th>\n",
       "      <th>when</th>\n",
       "      <th>were</th>\n",
       "      <th>husband</th>\n",
       "      <th>will</th>\n",
       "      <th>from</th>\n",
       "      <th>against</th>\n",
       "      <th>jun</th>\n",
       "      <th>2015</th>\n",
       "      <th>then</th>\n",
       "      <th>woman</th>\n",
       "      <th>love</th>\n",
       "      <th>him</th>\n",
       "      <th>d</th>\n",
       "      <th>my</th>\n",
       "      <th>s</th>\n",
       "      <th>his</th>\n",
       "      <th>he</th>\n",
       "      <th>rose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machado</th>\n",
       "      <td>-7.343399</td>\n",
       "      <td>-0.985465</td>\n",
       "      <td>-4.920475</td>\n",
       "      <td>-6.598802</td>\n",
       "      <td>-4.618643</td>\n",
       "      <td>-12.419423</td>\n",
       "      <td>-6.907539</td>\n",
       "      <td>-4.920280</td>\n",
       "      <td>-2.787690</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>-3.806771</td>\n",
       "      <td>-6.153043</td>\n",
       "      <td>-5.790650</td>\n",
       "      <td>-4.204068</td>\n",
       "      <td>-0.467731</td>\n",
       "      <td>-4.079823</td>\n",
       "      <td>-0.320036</td>\n",
       "      <td>-3.521321</td>\n",
       "      <td>-3.988454</td>\n",
       "      <td>-5.218091</td>\n",
       "      <td>-4.159371</td>\n",
       "      <td>-4.942890</td>\n",
       "      <td>-3.434823</td>\n",
       "      <td>-3.921923</td>\n",
       "      <td>-1.602298</td>\n",
       "      <td>-5.018877</td>\n",
       "      <td>-3.509677</td>\n",
       "      <td>2.430100</td>\n",
       "      <td>-2.641000</td>\n",
       "      <td>-1.566462</td>\n",
       "      <td>-7.292110</td>\n",
       "      <td>-2.348327</td>\n",
       "      <td>-4.185603</td>\n",
       "      <td>-5.450919</td>\n",
       "      <td>-3.996241</td>\n",
       "      <td>-0.162113</td>\n",
       "      <td>-2.437339</td>\n",
       "      <td>-4.145338</td>\n",
       "      <td>-2.969254</td>\n",
       "      <td>-0.790132</td>\n",
       "      <td>-2.997354</td>\n",
       "      <td>-1.828184</td>\n",
       "      <td>-2.689985</td>\n",
       "      <td>-1.190277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.898791</td>\n",
       "      <td>-1.824685</td>\n",
       "      <td>-2.460422</td>\n",
       "      <td>-2.377373</td>\n",
       "      <td>-1.370223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134672</td>\n",
       "      <td>1.459823</td>\n",
       "      <td>6.977786</td>\n",
       "      <td>0.816492</td>\n",
       "      <td>8.175080</td>\n",
       "      <td>8.964352</td>\n",
       "      <td>-1.271770</td>\n",
       "      <td>2.255112</td>\n",
       "      <td>0.299069</td>\n",
       "      <td>10.974233</td>\n",
       "      <td>-3.779533</td>\n",
       "      <td>0.910434</td>\n",
       "      <td>5.190975</td>\n",
       "      <td>5.190975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.358956</td>\n",
       "      <td>-4.899501</td>\n",
       "      <td>2.884848</td>\n",
       "      <td>-1.553357</td>\n",
       "      <td>0.404073</td>\n",
       "      <td>-0.277577</td>\n",
       "      <td>6.755001</td>\n",
       "      <td>4.185100</td>\n",
       "      <td>5.665579</td>\n",
       "      <td>-1.398438</td>\n",
       "      <td>9.844441</td>\n",
       "      <td>-1.250450</td>\n",
       "      <td>1.518332</td>\n",
       "      <td>1.765750</td>\n",
       "      <td>2.190363</td>\n",
       "      <td>7.011540</td>\n",
       "      <td>8.769149</td>\n",
       "      <td>3.170063</td>\n",
       "      <td>4.552359</td>\n",
       "      <td>8.700062</td>\n",
       "      <td>-0.512355</td>\n",
       "      <td>3.726362</td>\n",
       "      <td>1.303212</td>\n",
       "      <td>9.351161</td>\n",
       "      <td>9.787224</td>\n",
       "      <td>6.691444</td>\n",
       "      <td>9.463611</td>\n",
       "      <td>-8.961630</td>\n",
       "      <td>-2.256784</td>\n",
       "      <td>-7.748307</td>\n",
       "      <td>26.854746</td>\n",
       "      <td>10.893000</td>\n",
       "      <td>-1.886455</td>\n",
       "      <td>-3.620684</td>\n",
       "      <td>-6.366075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swirsky</th>\n",
       "      <td>-10.740881</td>\n",
       "      <td>-14.890550</td>\n",
       "      <td>-7.778889</td>\n",
       "      <td>-6.144661</td>\n",
       "      <td>-9.769340</td>\n",
       "      <td>-2.504517</td>\n",
       "      <td>-5.893138</td>\n",
       "      <td>-6.722751</td>\n",
       "      <td>-8.194708</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>-5.149635</td>\n",
       "      <td>-3.425073</td>\n",
       "      <td>-3.891471</td>\n",
       "      <td>-3.599310</td>\n",
       "      <td>-10.202977</td>\n",
       "      <td>-3.686210</td>\n",
       "      <td>-7.690669</td>\n",
       "      <td>-3.836762</td>\n",
       "      <td>-4.687791</td>\n",
       "      <td>-1.870954</td>\n",
       "      <td>-4.103489</td>\n",
       "      <td>-3.821410</td>\n",
       "      <td>-2.767152</td>\n",
       "      <td>-4.650814</td>\n",
       "      <td>-7.879098</td>\n",
       "      <td>-2.120800</td>\n",
       "      <td>-3.409770</td>\n",
       "      <td>-9.069397</td>\n",
       "      <td>-2.930531</td>\n",
       "      <td>-5.905844</td>\n",
       "      <td>-0.596477</td>\n",
       "      <td>-4.581654</td>\n",
       "      <td>-2.872510</td>\n",
       "      <td>-0.531475</td>\n",
       "      <td>-1.236145</td>\n",
       "      <td>-4.919787</td>\n",
       "      <td>-3.984399</td>\n",
       "      <td>-0.521873</td>\n",
       "      <td>-3.255841</td>\n",
       "      <td>-5.645614</td>\n",
       "      <td>-1.729547</td>\n",
       "      <td>-2.993184</td>\n",
       "      <td>-2.603030</td>\n",
       "      <td>-4.042340</td>\n",
       "      <td>-5.188043</td>\n",
       "      <td>-6.031405</td>\n",
       "      <td>-2.580656</td>\n",
       "      <td>-2.043532</td>\n",
       "      <td>-3.119118</td>\n",
       "      <td>-1.989211</td>\n",
       "      <td>...</td>\n",
       "      <td>4.072632</td>\n",
       "      <td>2.005536</td>\n",
       "      <td>-2.249852</td>\n",
       "      <td>3.383265</td>\n",
       "      <td>-3.732567</td>\n",
       "      <td>-4.071046</td>\n",
       "      <td>7.065640</td>\n",
       "      <td>2.428211</td>\n",
       "      <td>3.771497</td>\n",
       "      <td>-7.229800</td>\n",
       "      <td>8.414869</td>\n",
       "      <td>3.254530</td>\n",
       "      <td>-0.209587</td>\n",
       "      <td>-0.209587</td>\n",
       "      <td>6.004314</td>\n",
       "      <td>-3.911285</td>\n",
       "      <td>9.970373</td>\n",
       "      <td>0.451978</td>\n",
       "      <td>5.988648</td>\n",
       "      <td>3.810388</td>\n",
       "      <td>8.580404</td>\n",
       "      <td>-2.167075</td>\n",
       "      <td>0.173845</td>\n",
       "      <td>-2.497929</td>\n",
       "      <td>8.161367</td>\n",
       "      <td>-4.561452</td>\n",
       "      <td>7.382059</td>\n",
       "      <td>4.703701</td>\n",
       "      <td>2.659036</td>\n",
       "      <td>3.045592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.601775</td>\n",
       "      <td>3.527182</td>\n",
       "      <td>2.384317</td>\n",
       "      <td>-1.986760</td>\n",
       "      <td>8.008137</td>\n",
       "      <td>5.265388</td>\n",
       "      <td>7.419023</td>\n",
       "      <td>-0.036150</td>\n",
       "      <td>-0.371958</td>\n",
       "      <td>2.661344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.637015</td>\n",
       "      <td>16.067249</td>\n",
       "      <td>20.258468</td>\n",
       "      <td>-9.370058</td>\n",
       "      <td>4.110606</td>\n",
       "      <td>22.343143</td>\n",
       "      <td>23.184698</td>\n",
       "      <td>26.886043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valente</th>\n",
       "      <td>16.910226</td>\n",
       "      <td>12.136132</td>\n",
       "      <td>11.978301</td>\n",
       "      <td>11.860810</td>\n",
       "      <td>11.325783</td>\n",
       "      <td>11.010289</td>\n",
       "      <td>10.284368</td>\n",
       "      <td>10.202931</td>\n",
       "      <td>9.166470</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>8.954025</td>\n",
       "      <td>8.735275</td>\n",
       "      <td>8.385402</td>\n",
       "      <td>7.880258</td>\n",
       "      <td>7.811434</td>\n",
       "      <td>7.658614</td>\n",
       "      <td>7.561372</td>\n",
       "      <td>7.164359</td>\n",
       "      <td>7.116420</td>\n",
       "      <td>7.096671</td>\n",
       "      <td>7.093699</td>\n",
       "      <td>6.854533</td>\n",
       "      <td>6.836739</td>\n",
       "      <td>6.707473</td>\n",
       "      <td>6.685772</td>\n",
       "      <td>6.510298</td>\n",
       "      <td>6.361154</td>\n",
       "      <td>6.349802</td>\n",
       "      <td>6.342014</td>\n",
       "      <td>6.298453</td>\n",
       "      <td>6.154192</td>\n",
       "      <td>6.061780</td>\n",
       "      <td>6.041215</td>\n",
       "      <td>5.947806</td>\n",
       "      <td>5.775953</td>\n",
       "      <td>5.749492</td>\n",
       "      <td>5.711734</td>\n",
       "      <td>5.706972</td>\n",
       "      <td>5.483472</td>\n",
       "      <td>5.448154</td>\n",
       "      <td>5.157167</td>\n",
       "      <td>5.153720</td>\n",
       "      <td>5.026750</td>\n",
       "      <td>5.025413</td>\n",
       "      <td>4.991169</td>\n",
       "      <td>4.917788</td>\n",
       "      <td>4.911303</td>\n",
       "      <td>4.901795</td>\n",
       "      <td>4.801896</td>\n",
       "      <td>4.770819</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.562886</td>\n",
       "      <td>-3.572387</td>\n",
       "      <td>-3.625614</td>\n",
       "      <td>-3.789502</td>\n",
       "      <td>-3.809961</td>\n",
       "      <td>-3.813239</td>\n",
       "      <td>-3.851584</td>\n",
       "      <td>-3.860391</td>\n",
       "      <td>-3.869995</td>\n",
       "      <td>-3.891260</td>\n",
       "      <td>-3.902878</td>\n",
       "      <td>-3.909442</td>\n",
       "      <td>-3.929031</td>\n",
       "      <td>-3.929031</td>\n",
       "      <td>-4.115927</td>\n",
       "      <td>-4.148508</td>\n",
       "      <td>-4.166784</td>\n",
       "      <td>-4.175436</td>\n",
       "      <td>-4.261547</td>\n",
       "      <td>-4.349795</td>\n",
       "      <td>-4.428721</td>\n",
       "      <td>-4.720311</td>\n",
       "      <td>-4.764833</td>\n",
       "      <td>-4.827824</td>\n",
       "      <td>-4.916381</td>\n",
       "      <td>-4.930089</td>\n",
       "      <td>-4.990822</td>\n",
       "      <td>-5.062905</td>\n",
       "      <td>-5.131930</td>\n",
       "      <td>-5.367505</td>\n",
       "      <td>-5.701526</td>\n",
       "      <td>-6.137503</td>\n",
       "      <td>-6.257555</td>\n",
       "      <td>-6.418175</td>\n",
       "      <td>-6.724044</td>\n",
       "      <td>-6.754588</td>\n",
       "      <td>-7.478183</td>\n",
       "      <td>-7.785247</td>\n",
       "      <td>-8.095062</td>\n",
       "      <td>-8.146123</td>\n",
       "      <td>-8.164195</td>\n",
       "      <td>-8.776126</td>\n",
       "      <td>-9.021805</td>\n",
       "      <td>-10.805114</td>\n",
       "      <td>-10.939146</td>\n",
       "      <td>-12.745462</td>\n",
       "      <td>-12.868358</td>\n",
       "      <td>-14.832010</td>\n",
       "      <td>-16.732626</td>\n",
       "      <td>-17.882828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lion         we     called      lions         it        not  \\\n",
       "Machado  -7.343399  -0.985465  -4.920475  -6.598802  -4.618643 -12.419423   \n",
       "Swirsky -10.740881 -14.890550  -7.778889  -6.144661  -9.769340  -2.504517   \n",
       "Valente  16.910226  12.136132  11.978301  11.860810  11.325783  11.010289   \n",
       "\n",
       "                of     inside       did      hole  watering        in  \\\n",
       "Machado  -6.907539  -4.920280 -2.787690 -3.806771 -3.806771 -6.153043   \n",
       "Swirsky  -5.893138  -6.722751 -8.194708 -5.149635 -5.149635 -3.425073   \n",
       "Valente  10.284368  10.202931  9.166470  8.954025  8.954025  8.735275   \n",
       "\n",
       "            could      blue       like       big       had      well  \\\n",
       "Machado -5.790650 -4.204068  -0.467731 -4.079823 -0.320036 -3.521321   \n",
       "Swirsky -3.891471 -3.599310 -10.202977 -3.686210 -7.690669 -3.836762   \n",
       "Valente  8.385402  7.880258   7.811434  7.658614  7.561372  7.164359   \n",
       "\n",
       "               be      made  smallgod       one  dormouse    myself       you  \\\n",
       "Machado -3.988454 -5.218091 -4.159371 -4.942890 -3.434823 -3.921923 -1.602298   \n",
       "Swirsky -4.687791 -1.870954 -4.103489 -3.821410 -2.767152 -4.650814 -7.879098   \n",
       "Valente  7.116420  7.096671  7.093699  6.854533  6.836739  6.707473  6.685772   \n",
       "\n",
       "             long    uplink    mother     jewel     child       all     black  \\\n",
       "Machado -5.018877 -3.509677  2.430100 -2.641000 -1.566462 -7.292110 -2.348327   \n",
       "Swirsky -2.120800 -3.409770 -9.069397 -2.930531 -5.905844 -0.596477 -4.581654   \n",
       "Valente  6.510298  6.361154  6.349802  6.342014  6.298453  6.154192  6.061780   \n",
       "\n",
       "          machine     their     every      body   yttrium        us      done  \\\n",
       "Machado -4.185603 -5.450919 -3.996241 -0.162113 -2.437339 -4.145338 -2.969254   \n",
       "Swirsky -2.872510 -0.531475 -1.236145 -4.919787 -3.984399 -0.521873 -3.255841   \n",
       "Valente  6.041215  5.947806  5.775953  5.749492  5.711734  5.706972  5.483472   \n",
       "\n",
       "               me   perhaps  dreambody     means  anything  dreaming  \\\n",
       "Machado -0.790132 -2.997354  -1.828184 -2.689985 -1.190277  0.000000   \n",
       "Swirsky -5.645614 -1.729547  -2.993184 -2.603030 -4.042340 -5.188043   \n",
       "Valente  5.448154  5.157167   5.153720  5.026750  5.025413  4.991169   \n",
       "\n",
       "             have     green     house  steelveldt    really    ...      \\\n",
       "Machado -1.898791 -1.824685 -2.460422   -2.377373 -1.370223    ...       \n",
       "Swirsky -6.031405 -2.580656 -2.043532   -3.119118 -1.989211    ...       \n",
       "Valente  4.917788  4.911303  4.901795    4.801896  4.770819    ...       \n",
       "\n",
       "         laughter      feet     class       and    doctor      said     until  \\\n",
       "Machado -0.134672  1.459823  6.977786  0.816492  8.175080  8.964352 -1.271770   \n",
       "Swirsky  4.072632  2.005536 -2.249852  3.383265 -3.732567 -4.071046  7.065640   \n",
       "Valente -3.562886 -3.572387 -3.625614 -3.789502 -3.809961 -3.813239 -3.851584   \n",
       "\n",
       "             hand    father        SYM      okay   fingers         l  \\\n",
       "Machado  2.255112  0.299069  10.974233 -3.779533  0.910434  5.190975   \n",
       "Swirsky  2.428211  3.771497  -7.229800  8.414869  3.254530 -0.209587   \n",
       "Valente -3.860391 -3.869995  -3.891260 -3.902878 -3.909442 -3.929031   \n",
       "\n",
       "          lucille    toward       cal      bird      last      felt      cold  \\\n",
       "Machado  5.190975  0.000000  8.358956 -4.899501  2.884848 -1.553357  0.404073   \n",
       "Swirsky -0.209587  6.004314 -3.911285  9.970373  0.451978  5.988648  3.810388   \n",
       "Valente -3.929031 -4.115927 -4.148508 -4.166784 -4.175436 -4.261547 -4.349795   \n",
       "\n",
       "              she     after  something       see       the    ribbon  \\\n",
       "Machado -0.277577  6.755001   4.185100  5.665579 -1.398438  9.844441   \n",
       "Swirsky  8.580404 -2.167075   0.173845 -2.497929  8.161367 -4.561452   \n",
       "Valente -4.428721 -4.720311  -4.764833 -4.827824 -4.916381 -4.930089   \n",
       "\n",
       "           across   another       new      away        27     going      when  \\\n",
       "Machado -1.250450  1.518332  1.765750  2.190363  7.011540  8.769149  3.170063   \n",
       "Swirsky  7.382059  4.703701  2.659036  3.045592  0.000000 -4.601775  3.527182   \n",
       "Valente -4.990822 -5.062905 -5.131930 -5.367505 -5.701526 -6.137503 -6.257555   \n",
       "\n",
       "             were   husband      will      from   against       jun      2015  \\\n",
       "Machado  4.552359  8.700062 -0.512355  3.726362  1.303212  9.351161  9.787224   \n",
       "Swirsky  2.384317 -1.986760  8.008137  5.265388  7.419023 -0.036150 -0.371958   \n",
       "Valente -6.418175 -6.724044 -6.754588 -7.478183 -7.785247 -8.095062 -8.146123   \n",
       "\n",
       "             then     woman       love        him          d         my  \\\n",
       "Machado  6.691444  9.463611  -8.961630  -2.256784  -7.748307  26.854746   \n",
       "Swirsky  2.661344  0.000000  18.637015  16.067249  20.258468  -9.370058   \n",
       "Valente -8.164195 -8.776126  -9.021805 -10.805114 -10.939146 -12.745462   \n",
       "\n",
       "                 s        his         he       rose  \n",
       "Machado  10.893000  -1.886455  -3.620684  -6.366075  \n",
       "Swirsky   4.110606  22.343143  23.184698  26.886043  \n",
       "Valente -12.868358 -14.832010 -16.732626 -17.882828  \n",
       "\n",
       "[3 rows x 7768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nBest Training Set Score: {:.2%}'.format(grid.cv_results_['mean_train_score'][grid.best_index_]))\n",
    "print('\\nBest Cross-Val Score: {:.2%}'.format(grid.best_score_))\n",
    "\n",
    "print('\\nBest Parameters:\\n')\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('{}: {}'.format(param_name, best_parameters[param_name]))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_score = grid.score(X_test, y_test)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print('\\nTest set score: {:.1%}'.format(test_score))\n",
    "\n",
    "df_test_cm = pd.DataFrame(test_cm, index=grid.classes_, columns=grid.classes_)\n",
    "df_test_cm.index.name = 'Actual Author'\n",
    "df_test_cm.columns.name = 'Predicted Author'\n",
    "display(df_test_cm)\n",
    "\n",
    "feature_list1 = grid.best_estimator_.named_steps['union'].transformer_list[0][1].named_steps['vect'].get_feature_names()\n",
    "feature_list2 = grid.best_estimator_.named_steps['union'].transformer_list[1][1].named_steps['dict'].get_feature_names()\n",
    "feature_list = feature_list1 + feature_list2\n",
    "feature_coefficients = pd.DataFrame(grid.best_estimator_.steps[-1][1].coef_, columns=feature_list, index=grid.classes_)\n",
    "print('\\n{} features'.format(len(feature_list)))\n",
    "# columns=feature_list, \n",
    "display(feature_coefficients.sort_values('Machado', ascending=False, axis=1).head(10))\n",
    "display(feature_coefficients.sort_values('Swirsky', ascending=False, axis=1).head(10))\n",
    "display(feature_coefficients.sort_values('Valente', ascending=False, axis=1).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<method 'split' of 'str' objects>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=0.6,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "        preprocessor=None, smooth_idf=True, stop_words='english',\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.named_steps['union'].transformer_list[0][1].named_steps['vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'INTJ',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PART',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'SCONJ',\n",
       " 'SYM',\n",
       " 'VERB',\n",
       " 'length']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.named_steps['union'].transformer_list[1][1].named_steps['dict'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_union__text__vect__ngram_range</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.80</td>\n",
       "      <td>1.29</td>\n",
       "      <td>37.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>36.46</td>\n",
       "      <td>34.64</td>\n",
       "      <td>33.31</td>\n",
       "      <td>37.64</td>\n",
       "      <td>39.88</td>\n",
       "      <td>34.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.11</td>\n",
       "      <td>2.84</td>\n",
       "      <td>40.73</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>34.19</td>\n",
       "      <td>40.80</td>\n",
       "      <td>39.36</td>\n",
       "      <td>35.38</td>\n",
       "      <td>43.18</td>\n",
       "      <td>43.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.43</td>\n",
       "      <td>5.30</td>\n",
       "      <td>37.88</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>40.58</td>\n",
       "      <td>35.04</td>\n",
       "      <td>27.65</td>\n",
       "      <td>43.37</td>\n",
       "      <td>40.82</td>\n",
       "      <td>29.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.56</td>\n",
       "      <td>5.85</td>\n",
       "      <td>47.80</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>52.36</td>\n",
       "      <td>38.29</td>\n",
       "      <td>43.02</td>\n",
       "      <td>55.43</td>\n",
       "      <td>43.35</td>\n",
       "      <td>44.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.00</td>\n",
       "      <td>6.49</td>\n",
       "      <td>34.78</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>41.14</td>\n",
       "      <td>32.57</td>\n",
       "      <td>25.26</td>\n",
       "      <td>44.00</td>\n",
       "      <td>34.83</td>\n",
       "      <td>25.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.05</td>\n",
       "      <td>6.93</td>\n",
       "      <td>43.91</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>30.26</td>\n",
       "      <td>44.66</td>\n",
       "      <td>45.24</td>\n",
       "      <td>32.09</td>\n",
       "      <td>50.37</td>\n",
       "      <td>49.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.53</td>\n",
       "      <td>7.69</td>\n",
       "      <td>52.71</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>50.43</td>\n",
       "      <td>35.80</td>\n",
       "      <td>53.38</td>\n",
       "      <td>58.20</td>\n",
       "      <td>38.04</td>\n",
       "      <td>61.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.31</td>\n",
       "      <td>8.21</td>\n",
       "      <td>37.45</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>41.13</td>\n",
       "      <td>24.75</td>\n",
       "      <td>43.06</td>\n",
       "      <td>42.92</td>\n",
       "      <td>26.08</td>\n",
       "      <td>43.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.93</td>\n",
       "      <td>9.27</td>\n",
       "      <td>29.50</td>\n",
       "      <td>10.83</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>26.40</td>\n",
       "      <td>17.42</td>\n",
       "      <td>39.98</td>\n",
       "      <td>26.79</td>\n",
       "      <td>17.79</td>\n",
       "      <td>43.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "0            34.80            1.29             37.33             2.22   \n",
       "4            38.11            2.84             40.73             3.78   \n",
       "7            34.43            5.30             37.88             6.06   \n",
       "2            44.56            5.85             47.80             5.42   \n",
       "6            33.00            6.49             34.78             7.55   \n",
       "3            40.05            6.93             43.91             8.38   \n",
       "5            46.53            7.69             52.71            10.49   \n",
       "1            36.31            8.21             37.45             8.04   \n",
       "8            27.93            9.27             29.50            10.83   \n",
       "\n",
       "   mean_fit_time param_model__alpha param_union__text__vect__ngram_range  \\\n",
       "0           0.18              0.001                               (1, 1)   \n",
       "4           0.26             0.0001                               (1, 2)   \n",
       "7           0.21              1e-05                               (1, 2)   \n",
       "2           0.18              0.001                               (1, 3)   \n",
       "6           0.23              1e-05                               (1, 1)   \n",
       "3           0.20             0.0001                               (1, 1)   \n",
       "5           0.23             0.0001                               (1, 3)   \n",
       "1           0.19              0.001                               (1, 2)   \n",
       "8           0.18              1e-05                               (1, 3)   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0              36.46              34.64              33.31   \n",
       "4              34.19              40.80              39.36   \n",
       "7              40.58              35.04              27.65   \n",
       "2              52.36              38.29              43.02   \n",
       "6              41.14              32.57              25.26   \n",
       "3              30.26              44.66              45.24   \n",
       "5              50.43              35.80              53.38   \n",
       "1              41.13              24.75              43.06   \n",
       "8              26.40              17.42              39.98   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \n",
       "0               37.64               39.88               34.46  \n",
       "4               35.38               43.18               43.62  \n",
       "7               43.37               40.82               29.43  \n",
       "2               55.43               43.35               44.62  \n",
       "6               44.00               34.83               25.51  \n",
       "3               32.09               50.37               49.28  \n",
       "5               58.20               38.04               61.90  \n",
       "1               42.92               26.08               43.36  \n",
       "8               26.79               17.79               43.91  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame()\n",
    "cv_results['mean_test_score'] = (grid.cv_results_['mean_test_score'] * 100).round(2)\n",
    "cv_results['std_test_score'] = (grid.cv_results_['std_test_score'] * 100).round(2)\n",
    "cv_results['mean_train_score'] = (grid.cv_results_['mean_train_score'] * 100).round(2)\n",
    "cv_results['std_train_score'] = (grid.cv_results_['std_train_score'] * 100).round(2)\n",
    "cv_results['mean_fit_time'] = grid.cv_results_['mean_fit_time'].round(2)\n",
    "cv_results = cv_results.join(pd.DataFrame(grid.cv_results_).filter(like='param_'))\n",
    "cv_results['split0_test_score'] = (grid.cv_results_['split0_test_score'] * 100).round(2)\n",
    "cv_results['split1_test_score'] = (grid.cv_results_['split1_test_score'] * 100).round(2)\n",
    "cv_results['split2_test_score'] = (grid.cv_results_['split2_test_score'] * 100).round(2)\n",
    "cv_results['split0_train_score'] = (grid.cv_results_['split0_train_score'] * 100).round(2)\n",
    "cv_results['split1_train_score'] = (grid.cv_results_['split1_train_score'] * 100).round(2)\n",
    "cv_results['split2_train_score'] = (grid.cv_results_['split2_train_score'] * 100).round(2)\n",
    "cv_results.sort_values('std_test_score', ascending=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
